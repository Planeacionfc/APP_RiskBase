{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones para estrucuturar los datos de la vista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrfc._cyrfc import Connection, ABAPApplicationError\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "from datetime import datetime, timedelta\n",
    "import win32com.client as win32\n",
    "from pretty_html_table import build_table\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from typing import Dict, Any\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class SAPConnection:\n",
    "    def __init__(self, ashost, sysnr, client, user, passwd, lang):\n",
    "        \"\"\"\n",
    "        Inicializa la conexi√≥n a SAP.\n",
    "        \"\"\"\n",
    "        self.connection_params = {\n",
    "            'ashost': ashost,\n",
    "            'sysnr': sysnr,\n",
    "            'client': client,\n",
    "            'user': user,\n",
    "            'passwd': passwd,\n",
    "            'lang': lang\n",
    "        }\n",
    "        self.connection = None\n",
    "\n",
    "    def open_connection(self):\n",
    "        \"\"\"\n",
    "        Abre una conexi√≥n a SAP con los par√°metros especificados.\n",
    "        \"\"\"\n",
    "        if self.connection is None:\n",
    "            self.connection = Connection(**self.connection_params)\n",
    "        return self.connection\n",
    "\n",
    "    def close_connection(self):\n",
    "        \"\"\"\n",
    "        Cierra la conexi√≥n a SAP.\n",
    "        \"\"\"\n",
    "        if self.connection:\n",
    "            self.connection.close()\n",
    "            self.connection = None\n",
    "\n",
    "    def execute_query(self, query_name, view_id, parameters):\n",
    "        \"\"\"\n",
    "        Ejecuta una consulta a SAP con par√°metros din√°micos.\n",
    "\n",
    "        Args:\n",
    "            query_name (str): Nombre del query SAP.\n",
    "            view_id (str): ID de la vista.\n",
    "            parameters (list of tuples): Lista de par√°metros en formato (nombre, valor).\n",
    "\n",
    "        Returns:\n",
    "            dict: Resultado de la consulta.\n",
    "        \"\"\"\n",
    "        self.open_connection()\n",
    "        # Construir la lista de par√°metros din√°micamente\n",
    "        formatted_parameters = [{\"NAME\": p[0], \"VALUE\": p[1]} for p in parameters]\n",
    "        formatted_parameters += [\n",
    "        ]\n",
    "\n",
    "        print(\"üõ† Sending Parameters to SAP BW:\") ##DEBUGGING\n",
    "        for param in formatted_parameters:\n",
    "            print(f\"{param['NAME']} = {param['VALUE']}\")\n",
    "\n",
    "\n",
    "        try: \n",
    "            result = self.connection.call(\n",
    "                \"RRW3_GET_QUERY_VIEW_DATA\",\n",
    "                I_QUERY=query_name,\n",
    "                I_VIEW_ID=view_id,\n",
    "                I_T_PARAMETER=formatted_parameters\n",
    "            )\n",
    "            print(\"‚úÖ Query executed successfully!\") ##DEBUGGING\n",
    "            return result\n",
    "        except ABAPApplicationError as error:\n",
    "            print(\"Error en SAP: \" + error.message)\n",
    "            return None\n",
    "        finally:\n",
    "            self.close_connection()\n",
    "\n",
    "    def extract_axis_data(self, axis_data):\n",
    "        \"\"\" Extrae informaci√≥n de las columnas (metadatos) de los datos del eje.\n",
    "        \n",
    "        Args:\n",
    "            axis_data (list): Lista de diccionarios que representa los datos de los ejes de la respuesta de SAP.\n",
    "        \n",
    "        Returns:\n",
    "            pandas.DataFrame: DataFrame con la informaci√≥n de las columnas como CHANM y sus etiquetas CAPTION.\n",
    "        \"\"\"\n",
    "        column_info = []\n",
    "        # Iterar a trav√©s de todos los datos de los ejes\n",
    "        for data in axis_data:\n",
    "            for set_item in data['SET']:\n",
    "                # Agregar solo si el item es nuevo\n",
    "                if not any(d['CHANM'] == set_item['CHANM'] for d in column_info):\n",
    "                    column_info.append({\n",
    "                        'CHANM': set_item['CHANM'],\n",
    "                        'CAPTION': set_item['CAPTION']\n",
    "                    })\n",
    "    \n",
    "        return pd.DataFrame(column_info)\n",
    "\n",
    "    def extract_axis_info(self, axis_data):\n",
    "        \"\"\"\n",
    "        Extrae y muestra informaci√≥n detallada sobre cada eje para ayudar a comprender la estructura del cubo.\n",
    "\n",
    "        Args:\n",
    "            axis_data (list): Lista de diccionarios que contienen informaci√≥n sobre los ejes.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Un DataFrame que contiene detalles sobre cada eje y sus caracter√≠sticas.\n",
    "        \"\"\"\n",
    "        # Inicializaci√≥n de la lista para almacenar la informaci√≥n de los ejes\n",
    "        axis_info = []\n",
    "        # Iteraci√≥n a trav√©s de cada eje en los datos proporcionados\n",
    "        for axis in axis_data:\n",
    "            # Iteraci√≥n a trav√©s de cada caracter√≠stica del eje\n",
    "            for char in axis.get('CHARS', []):\n",
    "                axis_info.append({\n",
    "                    'AXIS': axis['AXIS'],\n",
    "                    'CHANM': char['CHANM'],\n",
    "                    'CAPTION': char['CAPTION'],\n",
    "                    'CHATYP': char['CHATYP'],\n",
    "                    'DETAILS': f\"Presentaciones: {char['CHAPRSNT']}, Atributos: {len(char.get('ATTRINM', []))}\"\n",
    "                })\n",
    "        # Creaci√≥n de un DataFrame con la informaci√≥n recopilada\n",
    "        return pd.DataFrame(axis_info)\n",
    "\n",
    "    def clean_data(self, axis_data, cell_data):\n",
    "        \"\"\"\n",
    "        Transforma los datos brutos de ejes y celdas del cubo SAP en un DataFrame estructurado.\n",
    "\n",
    "        Args:\n",
    "            axis_data (list): Lista que contiene detalles de los ejes (Columnas).\n",
    "            cell_data (list): Lista que contiene los valores de las celdas relacionados con los ejes.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Un DataFrame estructurado que combina tanto los datos de los ejes como de las celdas.\n",
    "        \"\"\"\n",
    "        # Extracci√≥n de detalles de los ejes\n",
    "        data = []\n",
    "        for entry in axis_data:\n",
    "            if entry['AXIS'] == '001':  # ejemplo, ajustar basado en el caso de uso real\n",
    "                for item in entry['SET']:\n",
    "                    data.append({\n",
    "                        'TUPLE_ORDINAL': item['TUPLE_ORDINAL'],\n",
    "                        'CHANM': item['CHANM'],\n",
    "                        'CAPTION': item['CAPTION'],\n",
    "                        'CHAVL': item['CHAVL'],\n",
    "                        'MONTH': item.get('CHAVL_EXT', '')  # campo de ejemplo\n",
    "                    })\n",
    "        \n",
    "        # Creaci√≥n de DataFrame a partir de los datos de los ejes\n",
    "        df_final_data = pd.DataFrame(data)\n",
    "        \n",
    "        # Creaci√≥n de DataFrame a partir de los datos de las celdas\n",
    "        #df_final_cells = pd.DataFrame(cell_data)\n",
    "        #df_final_cells = df_final_cells.rename(columns={'CELL_ORDINAL': 'TUPLE_ORDINAL'})\n",
    "        \n",
    "        # Fusi√≥n de los DataFrames en 'TUPLE_ORDINAL'\n",
    "        #merged_df_final = pd.merge(df_final_data, df_final_cells, on='TUPLE_ORDINAL', how='left')\n",
    "        \n",
    "        return df_final_data\n",
    "        #return merged_df_final #KEVIN\n",
    "\n",
    "    def data_structuring(self, df_final, axis_info=None, values=['CAPTION']):\n",
    "        \"\"\"\n",
    "        Organiza los datos en un formato estructurado, transformando filas repetidas en columnas.\n",
    "        \n",
    "        Args:\n",
    "            df_final (pd.DataFrame): DataFrame que contiene los datos a organizar.\n",
    "            axis_info (pd.DataFrame): DataFrame opcional que contiene informaci√≥n sobre los ejes para identificar las columnas din√°micamente.\n",
    "            values (list): Lista con los nombres de las columnas que desea obtener del df_final\n",
    "            \n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame organizado con filas repetidas transformadas en columnas.\n",
    "        \"\"\"\n",
    "        if axis_info is not None:\n",
    "            # Usamos la informaci√≥n del eje para identificar columnas CLAVE\n",
    "            key_columns = axis_info[axis_info['CHATYP'] == '1']['CHANM'].tolist()\n",
    "        \n",
    "        # Filtrar el DataFrame original para mantener solo las columnas CLAVE y sus valores\n",
    "        filtered_df_final = df_final[df_final['CHANM'].isin(key_columns)]\n",
    "        \n",
    "        # Usar pivot_table para manejar m√∫ltiples valores de 'values'\n",
    "        pivot_df_final = filtered_df_final.pivot_table(index='TUPLE_ORDINAL', columns='CHANM', \n",
    "                                        values=values, \n",
    "                                        aggfunc='last').reset_index()\n",
    "\n",
    "        # Aplanar las columnas Multindex resultantes\n",
    "        pivot_df_final.columns = [' '.join(col).strip() for col in pivot_df_final.columns.values]\n",
    "\n",
    "        # Construir diccionario de renombrado si axis_info est√° DISPONIBLE\n",
    "        if axis_info is not None:\n",
    "            rename_dict = {}\n",
    "            for _, row in axis_info.iterrows():\n",
    "                if row['CHANM'] in key_columns:\n",
    "                    for suffix in values:\n",
    "                        old_col_name = f\"{suffix} {row['CHANM']}\"\n",
    "                        new_col_name = f\"{row['CAPTION']}-{suffix}\"\n",
    "                        rename_dict[old_col_name] = new_col_name\n",
    "            pivot_df_final = pivot_df_final.rename(columns=rename_dict)\n",
    "\n",
    "        return pivot_df_final\n",
    "    \n",
    "    def extract_all_data(self, column_names: List[str],query_name, view_id, params) -> pd.DataFrame:\n",
    "\n",
    "        self.open_connection()\n",
    "        raw_data = self.execute_query(query_name, view_id, params)\n",
    "\n",
    "\n",
    "        # Obtenemos diccionario con los nombres originales de las columnas\n",
    "        axis_info = self.extract_axis_info(raw_data['E_AXIS_INFO'])\n",
    "        # Obtenemos informaci√≥n combinada y transformada\n",
    "        data_clean = self.clean_data(raw_data['E_AXIS_DATA'], raw_data['E_CELL_DATA'])\n",
    "        # Estructuramos columnas y filas para un mejor entendimiento y visualizaci√≥n\n",
    "        df_final_axis_values = self.data_structuring(data_clean, axis_info, ['CAPTION','CHAVL','VALUE']) #kevin\n",
    "        \n",
    "        for record in raw_data['E_CELL_DATA']:\n",
    "            print(record)\n",
    "        \n",
    "        # Extraer los datos de las celdas del cubo y organizarlos en un DataFrame\n",
    "        cell_records = [\n",
    "            {'CELL_ORDINAL': record['CELL_ORDINAL'], 'VALUE': record['VALUE']}\n",
    "            for record in raw_data['E_CELL_DATA']\n",
    "        ]\n",
    "        df_final_cell = pd.DataFrame(cell_records)\n",
    "\n",
    "        df_final_cell['Group'] = df_final_cell.index // (len(column_names))\n",
    "\n",
    "        # Generar el DataFrame con las columnas ordenadas de acuerdo a `column_names`\n",
    "        df_final_cell_values = pd.DataFrame({\n",
    "            name: df_final_cell.groupby('Group')['VALUE'].nth(i).values\n",
    "            for i, name in enumerate(column_names)\n",
    "        })\n",
    "        return df_final_cell_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consultar los datos de la vista en SAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_sap():\n",
    "    \"\"\"\n",
    "    Conecta a SAP y obtiene el stock del mes ANTERIOR al mes actual.\n",
    "    \"\"\"\n",
    "    today = datetime.now()\n",
    "    month = today.strftime(\"%m.%Y\")\n",
    "\n",
    "    sap_conn = SAPConnection(\n",
    "        ashost=os.getenv(\"ASHOST\"),\n",
    "        sysnr=os.getenv(\"SYSNR\"),\n",
    "        client=os.getenv(\"CLIENT\"),\n",
    "        user=os.getenv(\"USER_SAP\"),\n",
    "        passwd=os.getenv(\"PASSWORD_SAP\"),\n",
    "        lang=\"ES\",\n",
    "    )\n",
    "\n",
    "    params = [\n",
    "        (\"VAR_ID_6\", \"0I_CMNTH                      0004\"),\n",
    "        (\"VAR_VALUE_LOW_EXT_6\", month),\n",
    "        (\"VAR_VALUE_HIGH_EXT_6\", month),\n",
    "    ]\n",
    "\n",
    "    result = sap_conn.execute_query(\"ZICM_CM03_Q001\", \"Z_BASE_RIESGO\", params)\n",
    "\n",
    "    # Primero extraemos la informacion de los ejes y los limpiamos\n",
    "    axis_info = sap_conn.extract_axis_info(result[\"E_AXIS_INFO\"])\n",
    "\n",
    "    # Limpia los datos de la consulta y la informacion de las celdas\n",
    "    data_clean = sap_conn.clean_data(result[\"E_AXIS_DATA\"], result[\"E_CELL_DATA\"])\n",
    "\n",
    "    # Con la informacion de los ejes, estructuramos los datos para que se ajusten a la estructura de un DataFrame\n",
    "    df_final_axis_values = sap_conn.data_structuring(\n",
    "        data_clean, axis_info, [\"CAPTION\", \"CHAVL\"]\n",
    "    )\n",
    "\n",
    "    # Estos son los nombres de las columnas que se van a crear en el DataFrame final\n",
    "    column_names = ['Costo Unitario Real',\n",
    "                    'Inventario Disponibl', \n",
    "                    'Inventario No Dispon', \n",
    "                    'Valor OBSOLETO', \n",
    "                    'Valor BLOQUEADO MM', \n",
    "                    'Valor Total MM', \n",
    "                    'Permanencia'\n",
    "                ]\n",
    "\n",
    "    # Con la informacion de las celdas, creamos un diccionario que contiene los valores de cada celda\n",
    "    cell_records = [\n",
    "        {'CELL_ORDINAL': record['CELL_ORDINAL'], 'VALUE': record['VALUE']}\n",
    "        for record in result['E_CELL_DATA']\n",
    "    ]\n",
    "\n",
    "    # Con el diccionario, creamos un DataFrame que contiene los valores de las celdas\n",
    "    df_final_cell = pd.DataFrame(cell_records)\n",
    "\n",
    "    # Agregamos una columna 'Group' que indica a que grupo pertenece cada celda. Se hace con // (divisin entera)\n",
    "    df_final_cell['Group'] = df_final_cell.index // (len(column_names))\n",
    "\n",
    "    # Creamos un nuevo DataFrame que contiene los valores de las celdas agrupados por el grupo\n",
    "    df_final_cell_values = pd.DataFrame({\n",
    "        name: df_final_cell.groupby('Group')['VALUE'].nth(i).values\n",
    "        for i, name in enumerate(column_names)\n",
    "    })\n",
    "\n",
    "    # Finalmente, concatenamos los dos DataFrames en uno solo, con la informacion de los ejes y los valores de las celdas\n",
    "    df_final_combined = pd.concat([df_final_axis_values, df_final_cell_values], axis=1)\n",
    "\n",
    "    # Renombrar columnas\n",
    "    df_final_combined = df_final_combined.rename(\n",
    "        columns={\n",
    "            'Material-CAPTION': 'Descripci√≥n', \n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Eliminar columnas innecesarias\n",
    "    df_final_combined = df_final_combined.drop(\n",
    "        columns=[\n",
    "            \"TUPLE_ORDINAL\",\n",
    "            \"Lote-CAPTION\",\n",
    "            \"Fecha entrada-CAPTION\",\n",
    "            \"Centro-CAPTION\",\n",
    "            \"Unidad medida-CAPTION\",\n",
    "            \"Codigo Almacen Cliente-CAPTION\",\n",
    "            \"Rango Cobertura-CAPTION\",\n",
    "            \"Creado el-CAPTION\",\n",
    "            \"Fecha Bloqueado-CAPTION\",\n",
    "            \"Fecha Obsoleto-CAPTION\",\n",
    "            \"Fech. Fabricaci√≥n-CAPTION\",\n",
    "            \"Rango de Permanencia-CAPTION\",\n",
    "            \"Rango Bloqueado-CAPTION\",\n",
    "            \"Rango Vencidos-CAPTION\",\n",
    "            \"Rango Obsoleto-CAPTION\",\n",
    "            \"Rango Pr√≥ximos a Ven-CAPTION\",\n",
    "            \"Rango Pr√≥x.Vencer MM-CAPTION\",\n",
    "            \"Fech, Caducidad/Fech Pref. Consumo-CAPTION\",\n",
    "            \"A√±o natural/Mes-CHAVL\",\n",
    "            \"Indicador Stock Espec.-CHAVL\",\n",
    "            \"Marca de QM-CHAVL\",\n",
    "            \"Tipo Material Inventario-CHAVL\",\n",
    "            \"Negocio Inventarios-CHAVL\",\n",
    "            \"Tipo de Material (I)-CHAVL\",\n",
    "            \"N√∫m.stock.esp.-CHAVL\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Eliminar sufijos de los nombres de columnas\n",
    "    df_final_combined.columns = df_final_combined.columns.str.replace(\"-CHAVL\", \"\").str.replace(\n",
    "        \"-CAPTION\", \"\"\n",
    "    )\n",
    "\n",
    "    # Convertir todas las columnas a may√∫sculas\n",
    "    df_final_combined = df_final_combined.apply(\n",
    "        lambda x: x.str.upper() if x.dtype == \"object\" else x\n",
    "    )\n",
    "    df_final_combined.columns = df_final_combined.columns.str.upper()\n",
    "\n",
    "    # Convertir columnas num√©ricas\n",
    "    columnas_numericas = [\n",
    "        \"COSTO UNITARIO REAL\",\n",
    "        \"INVENTARIO DISPONIBL\",\n",
    "        \"INVENTARIO NO DISPON\",\n",
    "        \"VALOR OBSOLETO\",\n",
    "        \"VALOR BLOQUEADO MM\",\n",
    "        \"VALOR TOTAL MM\",\n",
    "        \"PERMANENCIA\",\n",
    "    ]\n",
    "\n",
    "    for col in columnas_numericas:\n",
    "        if col in df_final_combined.columns:\n",
    "            df_final_combined[col] = pd.to_numeric(df_final_combined[col], errors=\"coerce\")\n",
    "\n",
    "    # Convertir columnas de fechas\n",
    "    columnas_fecha = [\n",
    "        \"FECHA ENTRADA\",\n",
    "        \"CREADO EL\",\n",
    "        \"FECHA BLOQUEADO\",\n",
    "        \"FECHA OBSOLETO\",\n",
    "        \"FECH. FABRICACI√ìN\",\n",
    "        \"FECH, CADUCIDAD/FECH PREF. CONSUMO\",\n",
    "    ]\n",
    "\n",
    "    for col in columnas_fecha:\n",
    "        if col in df_final_combined.columns:\n",
    "            df_final_combined[col] = pd.to_datetime(\n",
    "                df_final_combined[col], errors=\"coerce\"\n",
    "            ).dt.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "    df_final_combined = pd.DataFrame(df_final_combined)\n",
    "\n",
    "    return df_final_combined\n",
    "\n",
    "def upload_dataframe_to_db(df_final_combined: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Sube el DataFrame 'df_final_combined' a la base de datos en la tabla 'InventarioBaseRiesgo'.\n",
    "    Se utiliza SQLAlchemy para establecer la conexi√≥n y el m√©todo to_sql de pandas para insertar\n",
    "    todos los registros (append). Se asume que la tabla ya existe y que los nombres de columnas en \n",
    "    el DataFrame coinciden exactamente con los de la tabla en la base de datos.\n",
    "    \n",
    "    Args:\n",
    "        df_final_combined (pd.DataFrame): DataFrame con las columnas y el orden requeridos.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    connection_string = (\n",
    "            \"mssql+pyodbc://{user}:{pwd}@{server}/{db}\"\n",
    "            \"?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "        ).format(\n",
    "            user=os.getenv(\"DB_USER\"),\n",
    "            pwd=os.getenv(\"DB_PASSWORD\"),\n",
    "            server=os.getenv(\"DB_SERVER\"),\n",
    "            db=os.getenv(\"DATABASE\")\n",
    "        )\n",
    "    \n",
    "    # Crear el engine de SQLAlchemy con fast_executemany habilitado\n",
    "    engine = create_engine(connection_string, fast_executemany=True)\n",
    "    \n",
    "    try:\n",
    "        # Insertar datos en la tabla InventarioBaseRiesgo. \n",
    "        # if_exists='append' se utiliza para agregar los datos sin reemplazar la tabla.\n",
    "        df_final_combined.to_sql(\n",
    "            name='InventarioBaseRiesgo',\n",
    "            con=engine,\n",
    "            if_exists='append',\n",
    "            index=False,\n",
    "            chunksize=1000  # Tama√±o del chunk para inserciones masivas\n",
    "        )\n",
    "        print(\"Datos subidos correctamente a InventarioBaseRiesgo.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error al subir el DataFrame a la base de datos:\", e)\n",
    "    finally:\n",
    "        engine.dispose()\n",
    "\n",
    "def export_dataframe_to_excel(df: pd.DataFrame, filename: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Exporta un DataFrame a un archivo Excel con la fecha actual y lo guarda en una ruta espec√≠fica.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame a exportar\n",
    "        filename: Nombre base del archivo (opcional)\n",
    "\n",
    "    Returns:\n",
    "        str: Ruta del archivo Excel creado\n",
    "    \"\"\"\n",
    "    # Definir la ruta de destino\n",
    "    output_dir = r\"C:\\Users\\prac.planeacionfi\\OneDrive - Prebel S.A BIC\\Escritorio\\PRUEBAS BASE RIESGO\"\n",
    "\n",
    "    # Crear el nombre del archivo con la fecha actual\n",
    "    current_date = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "    if not filename:\n",
    "        filename = f\"An√°lisis_BaseRiesgo_Final_{current_date}.xlsx\"\n",
    "\n",
    "    # Crear la ruta completa\n",
    "    file_path = os.path.join(output_dir, filename)\n",
    "\n",
    "    # Asegurar que el directorio existe\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Exportar a Excel\n",
    "    try:\n",
    "        df.to_excel(file_path, index=False, sheet_name=\"Base de Riesgo\")\n",
    "        print(f\"Archivo Excel creado exitosamente: {file_path}\")\n",
    "        return file_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error al exportar a Excel: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_avon_natura(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filtra un DataFrame para quedarse solo con los materiales\n",
    "    cuya 'MARCA DE QM' sea 'AVON' o 'NATURA'.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame original que contiene la columna 'MARCA DE QM'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Nuevo DataFrame con solo las filas de AVON y NATURA,\n",
    "                      reindexado de 0 a N-1.\n",
    "    \"\"\"\n",
    "    mask = df[\"MARCA DE QM\"].isin([\"AVON\", \"NATURA\"])\n",
    "    return df.loc[mask].reset_index(drop=True)\n",
    "\n",
    "def filter_marca_otros(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Devuelve solo las filas donde 'MARCA DE QM' NO sea ni 'AVON' ni 'NATURA'.\n",
    "    Esto permite trabajar con el resto de las marcas por separado.\n",
    "    \"\"\"\n",
    "    # Aseguramos uniformidad en may√∫sculas\n",
    "    df = df.copy()\n",
    "    df[\"MARCA DE QM\"] = df[\"MARCA DE QM\"].str.upper()\n",
    "    \n",
    "    # Filtramos inversamente\n",
    "    mask = ~df[\"MARCA DE QM\"].isin([\"AVON\", \"NATURA\"])\n",
    "    return df[mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ† Sending Parameters to SAP BW:\n",
      "VAR_ID_6 = 0I_CMNTH                      0004\n",
      "VAR_VALUE_LOW_EXT_6 = 05.2025\n",
      "VAR_VALUE_HIGH_EXT_6 = 05.2025\n",
      "‚úÖ Query executed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prac.planeacionfi\\AppData\\Local\\Temp\\ipykernel_24280\\600308896.py:143: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_final_combined[col] = pd.to_datetime(\n",
      "C:\\Users\\prac.planeacionfi\\AppData\\Local\\Temp\\ipykernel_24280\\600308896.py:143: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_final_combined[col] = pd.to_datetime(\n"
     ]
    }
   ],
   "source": [
    "# 1. Obtienes el DataFrame completo\n",
    "df_final_combined = get_data_sap()\n",
    "\n",
    "# 2. Filtro para obtener solo los datos de AVON y NATURA\n",
    "df_avon_natura = filter_avon_natura(df_final_combined)\n",
    "\n",
    "# 3. Filtro para obtener los datos de otras marcas\n",
    "df_otras_marcas = filter_marca_otros(df_final_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql_engine():\n",
    "    \"\"\"\n",
    "    Establece la conexi√≥n a SQL Server mediante SQLAlchemy.\n",
    "    Configura los datos de conexi√≥n utilizando variables de entorno.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        connection_string = (\n",
    "            \"mssql+pyodbc://{user}:{pwd}@{server}/{db}\"\n",
    "            \"?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "        ).format(\n",
    "            user=os.getenv(\"DB_USER\"),\n",
    "            pwd=os.getenv(\"DB_PASSWORD\"),\n",
    "            server=os.getenv(\"DB_SERVER\"),\n",
    "            db=os.getenv(\"DATABASE\")\n",
    "        )\n",
    "        engine = create_engine(connection_string)\n",
    "        print(\"Conexi√≥n exitosa a la base de datos.\")\n",
    "        return engine\n",
    "    except Exception as e:\n",
    "        print(f\"Error al conectar a la base de datos: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def execute_query(query):\n",
    "    \"\"\"\n",
    "    Ejecuta el query en la base de datos y retorna un DataFrame utilizando SQLAlchemy.\n",
    "    \"\"\"\n",
    "    engine = get_sql_engine()\n",
    "    try:\n",
    "        df = pd.read_sql(query, engine)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al ejecutar el query: {str(e)}\")\n",
    "        df = pd.DataFrame()  # Retorna un DataFrame vac√≠o en caso de error\n",
    "    finally:\n",
    "        engine.dispose()  # Cierra la conexi√≥n\n",
    "    return df\n",
    "\n",
    "def get_inventario_matriz():\n",
    "    \"\"\"\n",
    "    Extrae todos los registros de la tabla InventarioMatriz.\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        id_politica_base_riesgo,\n",
    "        subsegmento,\n",
    "        negocio,\n",
    "        estado,\n",
    "        cobertura\n",
    "    FROM InventarioMatriz\n",
    "    \"\"\"\n",
    "    return execute_query(query)\n",
    "\n",
    "def get_matrices_base_riesgo():\n",
    "    \"\"\"\n",
    "    Extrae todos los registros de la tabla MatrizBaseRiesgo.\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT\n",
    "        id_politica_base_riesgo,\n",
    "        concatenado,\n",
    "        segmento,\n",
    "        permanencia,\n",
    "        factor_prov,\n",
    "        clasificacion,\n",
    "        tipo_matriz\n",
    "    FROM MatrizBaseRiesgo\n",
    "    \"\"\"\n",
    "    return execute_query(query)\n",
    "\n",
    "def df_matrices_merge():\n",
    "    \"\"\"\n",
    "    Extrae los datos de ambas tablas, los unifica utilizando pd.merge() y convierte\n",
    "    todos los campos de texto a may√∫sculas de forma vectorizada.\n",
    "    \"\"\"\n",
    "    df_inventario = get_inventario_matriz()\n",
    "    df_matrices = get_matrices_base_riesgo()\n",
    "    \n",
    "    # Unificaci√≥n utilizando la columna en com√∫n 'id_politica_base_riesgo'\n",
    "    df_matrices_merge = pd.merge(df_inventario, df_matrices, \n",
    "                        on=\"id_politica_base_riesgo\", \n",
    "                        how=\"inner\")  # Cambia 'inner' por 'left' o 'outer' seg√∫n lo requieras\n",
    "    \n",
    "    # Convertir los campos de tipo string a may√∫sculas de forma vectorizada\n",
    "    for col in df_matrices_merge.select_dtypes(include=[\"object\"]).columns:\n",
    "        df_matrices_merge[col] = df_matrices_merge[col].str.upper()\n",
    "    \n",
    "    # Convertir 'factor_prov' a float y normalizarlo\n",
    "    df_matrices_merge['factor_prov'] = df_matrices_merge['factor_prov'].apply(lambda x: x/100)\n",
    "    \n",
    "    return df_matrices_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_matrices_avon_natura():\n",
    "    \"\"\"\n",
    "    Extrae los datos de ambas tablas, las unifica utilizando pd.merge(),\n",
    "    convierte todos los campos de texto a may√∫sculas de forma vectorizada,\n",
    "    normaliza el factor provisional y, finalmente, filtra solo las filas\n",
    "    donde 'tipo_matriz' == 'MATRIZ NATURACO'.\n",
    "    \"\"\"\n",
    "    # 1. Extraer los DataFrames base\n",
    "    df_inventario = get_inventario_matriz()\n",
    "    df_matrices   = get_matrices_base_riesgo()\n",
    "    \n",
    "    # 2. Unirlos por la clave for√°nea\n",
    "    df = pd.merge(\n",
    "        df_inventario,\n",
    "        df_matrices,\n",
    "        on=\"id_politica_base_riesgo\",\n",
    "        how=\"inner\"  # o 'left' / 'outer' seg√∫n necesidad\n",
    "    )\n",
    "    \n",
    "    # 3. Pasar a may√∫sculas todas las columnas de texto\n",
    "    text_cols = df.select_dtypes(include=\"object\").columns\n",
    "    for c in text_cols:\n",
    "        df[c] = df[c].str.upper()\n",
    "    \n",
    "    # 4. Normalizar el factor provisional (de porcentaje a [0‚Äì1])\n",
    "    df[\"factor_prov\"] = df[\"factor_prov\"].astype(float) / 100.0\n",
    "    \n",
    "    # 5. Filtrar solo las filas de 'Matriz NaturaCo'\n",
    "    #    (ten en cuenta que ya convertimos todo a may√∫sculas)\n",
    "    df = df[df[\"tipo_matriz\"] == \"MATRIZ NATURACO\"].reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def df_matrices_otros_tipos():\n",
    "    \"\"\"\n",
    "    Devuelve solo las filas de df_merge donde 'tipo_matriz' sea distinto de 'Matriz NaturaCo'.\n",
    "    √ötil para aislar todas las dem√°s matrices.\n",
    "    \"\"\"\n",
    "    # 1. Extraer los DataFrames base\n",
    "    df_inventario = get_inventario_matriz()\n",
    "    df_matrices   = get_matrices_base_riesgo()\n",
    "    \n",
    "    # 2. Unirlos por la clave for√°nea\n",
    "    df = pd.merge(\n",
    "        df_inventario,\n",
    "        df_matrices,\n",
    "        on=\"id_politica_base_riesgo\",\n",
    "        how=\"inner\"  # o 'left' / 'outer' seg√∫n necesidad\n",
    "    )\n",
    "    \n",
    "    # 3. Pasar a may√∫sculas todas las columnas de texto\n",
    "    text_cols = df.select_dtypes(include=\"object\").columns\n",
    "    for c in text_cols:\n",
    "        df[c] = df[c].str.upper()\n",
    "    \n",
    "    # 4. Normalizar el factor provisional (de porcentaje a [0‚Äì1])\n",
    "    df[\"factor_prov\"] = df[\"factor_prov\"].astype(float) / 100.0\n",
    "    \n",
    "    # Filtramos aquellas filas cuyo tipo de matriz NO sea 'MATRIZ NATURACO'\n",
    "    mask = df[\"tipo_matriz\"] != \"MATRIZ NATURACO\"\n",
    "    \n",
    "    return df[mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexi√≥n exitosa a la base de datos.\n",
      "Conexi√≥n exitosa a la base de datos.\n",
      "Conexi√≥n exitosa a la base de datos.\n",
      "Conexi√≥n exitosa a la base de datos.\n",
      "Conexi√≥n exitosa a la base de datos.\n",
      "Conexi√≥n exitosa a la base de datos.\n"
     ]
    }
   ],
   "source": [
    "df_matrices_merge = df_matrices_merge()\n",
    "df_matrices_avon_natura = df_matrices_avon_natura()\n",
    "df_matrices_otros_tipos = df_matrices_otros_tipos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id_politica_base_riesgo",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "subsegmento",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "negocio",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "estado",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "cobertura",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "concatenado",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "segmento",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "permanencia",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "factor_prov",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "clasificacion",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tipo_matriz",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "82d0c4b3-8923-4308-8350-329f970c90f6",
       "rows": [
        [
         "0",
         "36",
         null,
         null,
         null,
         "1.MENOR DE 90 DIAS",
         "EXPERTOS NO LOCALES1.MENOR DE 90 DIAS1.MENOR DE 90 DIAS",
         "EXPERTOS NO LOCALES",
         "1.MENOR DE 90 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "1",
         "37",
         null,
         null,
         null,
         "1.MENOR DE 90 DIAS",
         "EXPERTOS NO LOCALES1.MENOR DE 90 DIAS2.ENTRE 90 Y 180 DIAS",
         "EXPERTOS NO LOCALES",
         "2.ENTRE 90 Y 180 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "2",
         "38",
         null,
         null,
         null,
         "1.MENOR DE 90 DIAS",
         "EXPERTOS NO LOCALES1.MENOR DE 90 DIAS3.ENTRE 180 Y 270 DIAS",
         "EXPERTOS NO LOCALES",
         "3.ENTRE 180 Y 270 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "3",
         "39",
         null,
         null,
         null,
         "1.MENOR DE 90 DIAS",
         "EXPERTOS NO LOCALES1.MENOR DE 90 DIAS4.ENTRE 270 Y 360 DIAS",
         "EXPERTOS NO LOCALES",
         "4.ENTRE 270 Y 360 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "4",
         "40",
         null,
         null,
         null,
         "1.MENOR DE 90 DIAS",
         "EXPERTOS NO LOCALES1.MENOR DE 90 DIAS5.ENTRE 360 Y 540 DIAS",
         "EXPERTOS NO LOCALES",
         "5.ENTRE 360 Y 540 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "5",
         "41",
         null,
         null,
         null,
         "1.MENOR DE 90 DIAS",
         "EXPERTOS NO LOCALES1.MENOR DE 90 DIAS6.ENTRE 540 Y 720 DIAS",
         "EXPERTOS NO LOCALES",
         "6.ENTRE 540 Y 720 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "6",
         "42",
         null,
         null,
         null,
         "1.MENOR DE 90 DIAS",
         "EXPERTOS NO LOCALES1.MENOR DE 90 DIAS7.MAYOR DE 720 DIAS",
         "EXPERTOS NO LOCALES",
         "7.MAYOR DE 720 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "7",
         "43",
         null,
         null,
         null,
         "2.ENTRE 90 Y 180 DIAS",
         "EXPERTOS NO LOCALES2.ENTRE 90 Y 180 DIAS1.MENOR DE 90 DIAS",
         "EXPERTOS NO LOCALES",
         "1.MENOR DE 90 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "8",
         "44",
         null,
         null,
         null,
         "2.ENTRE 90 Y 180 DIAS",
         "EXPERTOS NO LOCALES2.ENTRE 90 Y 180 DIAS2.ENTRE 90 Y 180 DIAS",
         "EXPERTOS NO LOCALES",
         "2.ENTRE 90 Y 180 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "9",
         "45",
         null,
         null,
         null,
         "2.ENTRE 90 Y 180 DIAS",
         "EXPERTOS NO LOCALES2.ENTRE 90 Y 180 DIAS3.ENTRE 180 Y 270 DIAS",
         "EXPERTOS NO LOCALES",
         "3.ENTRE 180 Y 270 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "10",
         "46",
         null,
         null,
         null,
         "2.ENTRE 90 Y 180 DIAS",
         "EXPERTOS NO LOCALES2.ENTRE 90 Y 180 DIAS4.ENTRE 270 Y 360 DIAS",
         "EXPERTOS NO LOCALES",
         "4.ENTRE 270 Y 360 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "11",
         "47",
         null,
         null,
         null,
         "2.ENTRE 90 Y 180 DIAS",
         "EXPERTOS NO LOCALES2.ENTRE 90 Y 180 DIAS5.ENTRE 360 Y 540 DIAS",
         "EXPERTOS NO LOCALES",
         "5.ENTRE 360 Y 540 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "12",
         "48",
         null,
         null,
         null,
         "2.ENTRE 90 Y 180 DIAS",
         "EXPERTOS NO LOCALES2.ENTRE 90 Y 180 DIAS6.ENTRE 540 Y 720 DIAS",
         "EXPERTOS NO LOCALES",
         "6.ENTRE 540 Y 720 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "13",
         "49",
         null,
         null,
         null,
         "2.ENTRE 90 Y 180 DIAS",
         "EXPERTOS NO LOCALES2.ENTRE 90 Y 180 DIAS7.MAYOR DE 720 DIAS",
         "EXPERTOS NO LOCALES",
         "7.MAYOR DE 720 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "14",
         "50",
         null,
         null,
         null,
         "3.ENTRE 180 Y 270 DIAS",
         "EXPERTOS NO LOCALES3.ENTRE 180 Y 270 DIAS1.MENOR DE 90 DIAS",
         "EXPERTOS NO LOCALES",
         "1.MENOR DE 90 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "15",
         "51",
         null,
         null,
         null,
         "3.ENTRE 180 Y 270 DIAS",
         "EXPERTOS NO LOCALES3.ENTRE 180 Y 270 DIAS2.ENTRE 90 Y 180 DIAS",
         "EXPERTOS NO LOCALES",
         "2.ENTRE 90 Y 180 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "16",
         "52",
         null,
         null,
         null,
         "3.ENTRE 180 Y 270 DIAS",
         "EXPERTOS NO LOCALES3.ENTRE 180 Y 270 DIAS3.ENTRE 180 Y 270 DIAS",
         "EXPERTOS NO LOCALES",
         "3.ENTRE 180 Y 270 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "17",
         "53",
         null,
         null,
         null,
         "3.ENTRE 180 Y 270 DIAS",
         "EXPERTOS NO LOCALES3.ENTRE 180 Y 270 DIAS4.ENTRE 270 Y 360 DIAS",
         "EXPERTOS NO LOCALES",
         "4.ENTRE 270 Y 360 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "18",
         "54",
         null,
         null,
         null,
         "3.ENTRE 180 Y 270 DIAS",
         "EXPERTOS NO LOCALES3.ENTRE 180 Y 270 DIAS5.ENTRE 360 Y 540 DIAS",
         "EXPERTOS NO LOCALES",
         "5.ENTRE 360 Y 540 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "19",
         "55",
         null,
         null,
         null,
         "3.ENTRE 180 Y 270 DIAS",
         "EXPERTOS NO LOCALES3.ENTRE 180 Y 270 DIAS6.ENTRE 540 Y 720 DIAS",
         "EXPERTOS NO LOCALES",
         "6.ENTRE 540 Y 720 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "20",
         "56",
         null,
         null,
         null,
         "3.ENTRE 180 Y 270 DIAS",
         "EXPERTOS NO LOCALES3.ENTRE 180 Y 270 DIAS7.MAYOR DE 720 DIAS",
         "EXPERTOS NO LOCALES",
         "7.MAYOR DE 720 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "21",
         "57",
         null,
         null,
         null,
         "4.ENTRE 270 Y 360 DIAS",
         "EXPERTOS NO LOCALES4.ENTRE 270 Y 360 DIAS1.MENOR DE 90 DIAS",
         "EXPERTOS NO LOCALES",
         "1.MENOR DE 90 DIAS",
         "0.0",
         "MEDIO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "22",
         "58",
         null,
         null,
         null,
         "4.ENTRE 270 Y 360 DIAS",
         "EXPERTOS NO LOCALES4.ENTRE 270 Y 360 DIAS2.ENTRE 90 Y 180 DIAS",
         "EXPERTOS NO LOCALES",
         "2.ENTRE 90 Y 180 DIAS",
         "0.0",
         "MEDIO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "23",
         "59",
         null,
         null,
         null,
         "4.ENTRE 270 Y 360 DIAS",
         "EXPERTOS NO LOCALES4.ENTRE 270 Y 360 DIAS3.ENTRE 180 Y 270 DIAS",
         "EXPERTOS NO LOCALES",
         "3.ENTRE 180 Y 270 DIAS",
         "0.0",
         "MEDIO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "24",
         "60",
         null,
         null,
         null,
         "4.ENTRE 270 Y 360 DIAS",
         "EXPERTOS NO LOCALES4.ENTRE 270 Y 360 DIAS4.ENTRE 270 Y 360 DIAS",
         "EXPERTOS NO LOCALES",
         "4.ENTRE 270 Y 360 DIAS",
         "0.0",
         "MEDIO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "25",
         "61",
         null,
         null,
         null,
         "4.ENTRE 270 Y 360 DIAS",
         "EXPERTOS NO LOCALES4.ENTRE 270 Y 360 DIAS5.ENTRE 360 Y 540 DIAS",
         "EXPERTOS NO LOCALES",
         "5.ENTRE 360 Y 540 DIAS",
         "0.3",
         "MEDIO-ALTO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "26",
         "62",
         null,
         null,
         null,
         "4.ENTRE 270 Y 360 DIAS",
         "EXPERTOS NO LOCALES4.ENTRE 270 Y 360 DIAS6.ENTRE 540 Y 720 DIAS",
         "EXPERTOS NO LOCALES",
         "6.ENTRE 540 Y 720 DIAS",
         "0.3",
         "MEDIO-ALTO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "27",
         "63",
         null,
         null,
         null,
         "4.ENTRE 270 Y 360 DIAS",
         "EXPERTOS NO LOCALES4.ENTRE 270 Y 360 DIAS7.MAYOR DE 720 DIAS",
         "EXPERTOS NO LOCALES",
         "7.MAYOR DE 720 DIAS",
         "0.5",
         "ALTO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "28",
         "64",
         null,
         null,
         null,
         "5.MAYOR O IGUAL A 360 DIAS",
         "EXPERTOS NO LOCALES5.MAYOR O IGUAL A 360 DIAS1.MENOR DE 90 DIAS",
         "EXPERTOS NO LOCALES",
         "1.MENOR DE 90 DIAS",
         "0.0",
         "MEDIO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "29",
         "65",
         null,
         null,
         null,
         "5.MAYOR O IGUAL A 360 DIAS",
         "EXPERTOS NO LOCALES5.MAYOR O IGUAL A 360 DIAS2.ENTRE 90 Y 180 DIAS",
         "EXPERTOS NO LOCALES",
         "2.ENTRE 90 Y 180 DIAS",
         "0.0",
         "MEDIO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "30",
         "66",
         null,
         null,
         null,
         "5.MAYOR O IGUAL A 360 DIAS",
         "EXPERTOS NO LOCALES5.MAYOR O IGUAL A 360 DIAS3.ENTRE 180 Y 270 DIAS",
         "EXPERTOS NO LOCALES",
         "3.ENTRE 180 Y 270 DIAS",
         "0.0",
         "MEDIO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "31",
         "67",
         null,
         null,
         null,
         "5.MAYOR O IGUAL A 360 DIAS",
         "EXPERTOS NO LOCALES5.MAYOR O IGUAL A 360 DIAS4.ENTRE 270 Y 360 DIAS",
         "EXPERTOS NO LOCALES",
         "4.ENTRE 270 Y 360 DIAS",
         "0.3",
         "MEDIO-ALTO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "32",
         "68",
         null,
         null,
         null,
         "5.MAYOR O IGUAL A 360 DIAS",
         "EXPERTOS NO LOCALES5.MAYOR O IGUAL A 360 DIAS5.ENTRE 360 Y 540 DIAS",
         "EXPERTOS NO LOCALES",
         "5.ENTRE 360 Y 540 DIAS",
         "0.3",
         "MEDIO-ALTO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "33",
         "69",
         null,
         null,
         null,
         "5.MAYOR O IGUAL A 360 DIAS",
         "EXPERTOS NO LOCALES5.MAYOR O IGUAL A 360 DIAS6.ENTRE 540 Y 720 DIAS",
         "EXPERTOS NO LOCALES",
         "6.ENTRE 540 Y 720 DIAS",
         "0.5",
         "ALTO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "34",
         "70",
         null,
         null,
         null,
         "5.MAYOR O IGUAL A 360 DIAS",
         "EXPERTOS NO LOCALES5.MAYOR O IGUAL A 360 DIAS7.MAYOR DE 720 DIAS",
         "EXPERTOS NO LOCALES",
         "7.MAYOR DE 720 DIAS",
         "1.0",
         "MUY ALTO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "35",
         "71",
         null,
         null,
         null,
         "1.MENOR DE 90 DIAS",
         "MARCAS PROPIAS1.MENOR DE 90 DIAS1.MENOR DE 90 DIAS",
         "MARCAS PROPIAS",
         "1.MENOR DE 90 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "36",
         "72",
         null,
         null,
         null,
         "1.MENOR DE 90 DIAS",
         "MARCAS PROPIAS1.MENOR DE 90 DIAS2.ENTRE 90 Y 180 DIAS",
         "MARCAS PROPIAS",
         "2.ENTRE 90 Y 180 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "37",
         "73",
         null,
         null,
         null,
         "1.MENOR DE 90 DIAS",
         "MARCAS PROPIAS1.MENOR DE 90 DIAS3.ENTRE 180 Y 270 DIAS",
         "MARCAS PROPIAS",
         "3.ENTRE 90 Y 180 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "38",
         "74",
         null,
         null,
         null,
         "1.MENOR DE 90 DIAS",
         "MARCAS PROPIAS1.MENOR DE 90 DIAS4.ENTRE 270 Y 360 DIAS",
         "MARCAS PROPIAS",
         "4.ENTRE 270 Y 360 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "39",
         "75",
         null,
         null,
         null,
         "1.MENOR DE 90 DIAS",
         "MARCAS PROPIAS1.MENOR DE 90 DIAS5.ENTRE 360 Y 540 DIAS",
         "MARCAS PROPIAS",
         "5.ENTRE 360 Y 540 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "40",
         "76",
         null,
         null,
         null,
         "1.MENOR DE 90 DIAS",
         "MARCAS PROPIAS1.MENOR DE 90 DIAS6.ENTRE 540 Y 720 DIAS",
         "MARCAS PROPIAS",
         "6.ENTRE 540 Y 720 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "41",
         "77",
         null,
         null,
         null,
         "1.MENOR DE 90 DIAS",
         "MARCAS PROPIAS1.MENOR DE 90 DIAS7.MAYOR DE 720 DIAS",
         "MARCAS PROPIAS",
         "7.MAYOR DE 720 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "42",
         "78",
         null,
         null,
         null,
         "2.ENTRE 90 Y 180 DIAS",
         "MARCAS PROPIAS2.ENTRE 90 Y 180 DIAS1.MENOR DE 90 DIAS",
         "MARCAS PROPIAS",
         "1.MENOR DE 90 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "43",
         "79",
         null,
         null,
         null,
         "2.ENTRE 90 Y 180 DIAS",
         "MARCAS PROPIAS2.ENTRE 90 Y 180 DIAS2.ENTRE 90 Y 180 DIAS",
         "MARCAS PROPIAS",
         "2.ENTRE 90 Y 180 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "44",
         "80",
         null,
         null,
         null,
         "2.ENTRE 90 Y 180 DIAS",
         "MARCAS PROPIAS2.ENTRE 90 Y 180 DIAS3.ENTRE 180 Y 270 DIAS",
         "MARCAS PROPIAS",
         "3.ENTRE 90 Y 180 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "45",
         "81",
         null,
         null,
         null,
         "2.ENTRE 90 Y 180 DIAS",
         "MARCAS PROPIAS2.ENTRE 90 Y 180 DIAS4.ENTRE 270 Y 360 DIAS",
         "MARCAS PROPIAS",
         "4.ENTRE 270 Y 360 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "46",
         "82",
         null,
         null,
         null,
         "2.ENTRE 90 Y 180 DIAS",
         "MARCAS PROPIAS2.ENTRE 90 Y 180 DIAS5.ENTRE 360 Y 540 DIAS",
         "MARCAS PROPIAS",
         "5.ENTRE 360 Y 540 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "47",
         "83",
         null,
         null,
         null,
         "2.ENTRE 90 Y 180 DIAS",
         "MARCAS PROPIAS2.ENTRE 90 Y 180 DIAS6.ENTRE 540 Y 720 DIAS",
         "MARCAS PROPIAS",
         "6.ENTRE 540 Y 720 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "48",
         "84",
         null,
         null,
         null,
         "2.ENTRE 90 Y 180 DIAS",
         "MARCAS PROPIAS2.ENTRE 90 Y 180 DIAS7.MAYOR DE 720 DIAS",
         "MARCAS PROPIAS",
         "7.MAYOR DE 720 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ],
        [
         "49",
         "85",
         null,
         null,
         null,
         "3.ENTRE 180 Y 270 DIAS",
         "MARCAS PROPIAS3.ENTRE 180 Y 270 DIAS1.MENOR DE 90 DIAS",
         "MARCAS PROPIAS",
         "1.MENOR DE 90 DIAS",
         "0.0",
         "BAJO",
         "MATRIZ DISPONIBLES VMI"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 1120
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_politica_base_riesgo</th>\n",
       "      <th>subsegmento</th>\n",
       "      <th>negocio</th>\n",
       "      <th>estado</th>\n",
       "      <th>cobertura</th>\n",
       "      <th>concatenado</th>\n",
       "      <th>segmento</th>\n",
       "      <th>permanencia</th>\n",
       "      <th>factor_prov</th>\n",
       "      <th>clasificacion</th>\n",
       "      <th>tipo_matriz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.MENOR DE 90 DIAS</td>\n",
       "      <td>EXPERTOS NO LOCALES1.MENOR DE 90 DIAS1.MENOR D...</td>\n",
       "      <td>EXPERTOS NO LOCALES</td>\n",
       "      <td>1.MENOR DE 90 DIAS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BAJO</td>\n",
       "      <td>MATRIZ DISPONIBLES VMI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.MENOR DE 90 DIAS</td>\n",
       "      <td>EXPERTOS NO LOCALES1.MENOR DE 90 DIAS2.ENTRE 9...</td>\n",
       "      <td>EXPERTOS NO LOCALES</td>\n",
       "      <td>2.ENTRE 90 Y 180 DIAS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BAJO</td>\n",
       "      <td>MATRIZ DISPONIBLES VMI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.MENOR DE 90 DIAS</td>\n",
       "      <td>EXPERTOS NO LOCALES1.MENOR DE 90 DIAS3.ENTRE 1...</td>\n",
       "      <td>EXPERTOS NO LOCALES</td>\n",
       "      <td>3.ENTRE 180 Y 270 DIAS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BAJO</td>\n",
       "      <td>MATRIZ DISPONIBLES VMI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.MENOR DE 90 DIAS</td>\n",
       "      <td>EXPERTOS NO LOCALES1.MENOR DE 90 DIAS4.ENTRE 2...</td>\n",
       "      <td>EXPERTOS NO LOCALES</td>\n",
       "      <td>4.ENTRE 270 Y 360 DIAS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BAJO</td>\n",
       "      <td>MATRIZ DISPONIBLES VMI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.MENOR DE 90 DIAS</td>\n",
       "      <td>EXPERTOS NO LOCALES1.MENOR DE 90 DIAS5.ENTRE 3...</td>\n",
       "      <td>EXPERTOS NO LOCALES</td>\n",
       "      <td>5.ENTRE 360 Y 540 DIAS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BAJO</td>\n",
       "      <td>MATRIZ DISPONIBLES VMI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>1151</td>\n",
       "      <td>TOLL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5.MAYOR O IGUAL A 360 DIAS</td>\n",
       "      <td>EXPERTOS LOCALESTOLL5.MAYOR O IGUAL A 360 DIAS...</td>\n",
       "      <td>EXPERTOS LOCALES</td>\n",
       "      <td>3.ENTRE 180 Y 270 DIAS</td>\n",
       "      <td>0.8</td>\n",
       "      <td>MUY ALTO</td>\n",
       "      <td>PVA 4 A 6 MESES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>1152</td>\n",
       "      <td>TOLL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5.MAYOR O IGUAL A 360 DIAS</td>\n",
       "      <td>EXPERTOS LOCALESTOLL5.MAYOR O IGUAL A 360 DIAS...</td>\n",
       "      <td>EXPERTOS LOCALES</td>\n",
       "      <td>4.ENTRE 270 Y 360 DIAS</td>\n",
       "      <td>0.8</td>\n",
       "      <td>MUY ALTO</td>\n",
       "      <td>PVA 4 A 6 MESES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>1153</td>\n",
       "      <td>TOLL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5.MAYOR O IGUAL A 360 DIAS</td>\n",
       "      <td>EXPERTOS LOCALESTOLL5.MAYOR O IGUAL A 360 DIAS...</td>\n",
       "      <td>EXPERTOS LOCALES</td>\n",
       "      <td>5.ENTRE 360 Y 540 DIAS</td>\n",
       "      <td>0.8</td>\n",
       "      <td>MUY ALTO</td>\n",
       "      <td>PVA 4 A 6 MESES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>1154</td>\n",
       "      <td>TOLL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5.MAYOR O IGUAL A 360 DIAS</td>\n",
       "      <td>EXPERTOS LOCALESTOLL5.MAYOR O IGUAL A 360 DIAS...</td>\n",
       "      <td>EXPERTOS LOCALES</td>\n",
       "      <td>6.ENTRE 540 Y 720 DIAS</td>\n",
       "      <td>0.8</td>\n",
       "      <td>MUY ALTO</td>\n",
       "      <td>PVA 4 A 6 MESES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>1155</td>\n",
       "      <td>TOLL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5.MAYOR O IGUAL A 360 DIAS</td>\n",
       "      <td>EXPERTOS LOCALESTOLL5.MAYOR O IGUAL A 360 DIAS...</td>\n",
       "      <td>EXPERTOS LOCALES</td>\n",
       "      <td>7.MAYOR DE 720 DIAS</td>\n",
       "      <td>0.8</td>\n",
       "      <td>MUY ALTO</td>\n",
       "      <td>PVA 4 A 6 MESES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1120 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_politica_base_riesgo subsegmento negocio estado  \\\n",
       "0                          36        None    None   None   \n",
       "1                          37        None    None   None   \n",
       "2                          38        None    None   None   \n",
       "3                          39        None    None   None   \n",
       "4                          40        None    None   None   \n",
       "...                       ...         ...     ...    ...   \n",
       "1115                     1151        TOLL    None   None   \n",
       "1116                     1152        TOLL    None   None   \n",
       "1117                     1153        TOLL    None   None   \n",
       "1118                     1154        TOLL    None   None   \n",
       "1119                     1155        TOLL    None   None   \n",
       "\n",
       "                       cobertura  \\\n",
       "0             1.MENOR DE 90 DIAS   \n",
       "1             1.MENOR DE 90 DIAS   \n",
       "2             1.MENOR DE 90 DIAS   \n",
       "3             1.MENOR DE 90 DIAS   \n",
       "4             1.MENOR DE 90 DIAS   \n",
       "...                          ...   \n",
       "1115  5.MAYOR O IGUAL A 360 DIAS   \n",
       "1116  5.MAYOR O IGUAL A 360 DIAS   \n",
       "1117  5.MAYOR O IGUAL A 360 DIAS   \n",
       "1118  5.MAYOR O IGUAL A 360 DIAS   \n",
       "1119  5.MAYOR O IGUAL A 360 DIAS   \n",
       "\n",
       "                                            concatenado             segmento  \\\n",
       "0     EXPERTOS NO LOCALES1.MENOR DE 90 DIAS1.MENOR D...  EXPERTOS NO LOCALES   \n",
       "1     EXPERTOS NO LOCALES1.MENOR DE 90 DIAS2.ENTRE 9...  EXPERTOS NO LOCALES   \n",
       "2     EXPERTOS NO LOCALES1.MENOR DE 90 DIAS3.ENTRE 1...  EXPERTOS NO LOCALES   \n",
       "3     EXPERTOS NO LOCALES1.MENOR DE 90 DIAS4.ENTRE 2...  EXPERTOS NO LOCALES   \n",
       "4     EXPERTOS NO LOCALES1.MENOR DE 90 DIAS5.ENTRE 3...  EXPERTOS NO LOCALES   \n",
       "...                                                 ...                  ...   \n",
       "1115  EXPERTOS LOCALESTOLL5.MAYOR O IGUAL A 360 DIAS...     EXPERTOS LOCALES   \n",
       "1116  EXPERTOS LOCALESTOLL5.MAYOR O IGUAL A 360 DIAS...     EXPERTOS LOCALES   \n",
       "1117  EXPERTOS LOCALESTOLL5.MAYOR O IGUAL A 360 DIAS...     EXPERTOS LOCALES   \n",
       "1118  EXPERTOS LOCALESTOLL5.MAYOR O IGUAL A 360 DIAS...     EXPERTOS LOCALES   \n",
       "1119  EXPERTOS LOCALESTOLL5.MAYOR O IGUAL A 360 DIAS...     EXPERTOS LOCALES   \n",
       "\n",
       "                 permanencia  factor_prov clasificacion  \\\n",
       "0         1.MENOR DE 90 DIAS          0.0          BAJO   \n",
       "1      2.ENTRE 90 Y 180 DIAS          0.0          BAJO   \n",
       "2     3.ENTRE 180 Y 270 DIAS          0.0          BAJO   \n",
       "3     4.ENTRE 270 Y 360 DIAS          0.0          BAJO   \n",
       "4     5.ENTRE 360 Y 540 DIAS          0.0          BAJO   \n",
       "...                      ...          ...           ...   \n",
       "1115  3.ENTRE 180 Y 270 DIAS          0.8      MUY ALTO   \n",
       "1116  4.ENTRE 270 Y 360 DIAS          0.8      MUY ALTO   \n",
       "1117  5.ENTRE 360 Y 540 DIAS          0.8      MUY ALTO   \n",
       "1118  6.ENTRE 540 Y 720 DIAS          0.8      MUY ALTO   \n",
       "1119     7.MAYOR DE 720 DIAS          0.8      MUY ALTO   \n",
       "\n",
       "                 tipo_matriz  \n",
       "0     MATRIZ DISPONIBLES VMI  \n",
       "1     MATRIZ DISPONIBLES VMI  \n",
       "2     MATRIZ DISPONIBLES VMI  \n",
       "3     MATRIZ DISPONIBLES VMI  \n",
       "4     MATRIZ DISPONIBLES VMI  \n",
       "...                      ...  \n",
       "1115         PVA 4 A 6 MESES  \n",
       "1116         PVA 4 A 6 MESES  \n",
       "1117         PVA 4 A 6 MESES  \n",
       "1118         PVA 4 A 6 MESES  \n",
       "1119         PVA 4 A 6 MESES  \n",
       "\n",
       "[1120 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_matrices_otros_tipos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L√≥gica para AVON y NATURA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_marks() -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Retorna un diccionario con el mapeo de marcas QM a marcas concatenadas.\n",
    "    \"\"\"\n",
    "    # TODO: Implementar el diccionario de marcas seg√∫n la l√≥gica de negocio\n",
    "    return {\n",
    "        \"ACCESORIOS\": \"ACCESORIOS\",\n",
    "        \"ADIDAS\": \"ADIDAS\",\n",
    "        \"AGATHA RUIZ DE LA PRADA\": \"AGATHA RUIZ DE LA PRADA\",\n",
    "        \"ALICORP\": \"ALICORP\",\n",
    "        \"AMAZON\": \"AMAZON\",\n",
    "        \"AMWAY\": \"AMWAY\",\n",
    "        \"ARDEN FOR MEN\": \"AFM/CFM\",\n",
    "        \"AVON\": \"AVON\",\n",
    "        \"BALANCE\": \"BALANCE\",\n",
    "        \"BANCO PREBEL\": \"BANCO PREBEL\",\n",
    "        \"BEAUTYHOLICS\": \"UTOPICK\",\n",
    "        \"BIO OIL\": \"BIO OIL\",\n",
    "        \"BIOTECNIK\": \"BIOTECNIK\",\n",
    "        \"BURTS_BEES\": \"BURT'S BEES\",\n",
    "        \"CADIVEU\": \"CADIVEU\",\n",
    "        \"calculateA\": \"calculateA\",\n",
    "        \"CATRICE\": \"CATRICE\",\n",
    "        \"CONNECT FOR MEN\": \"AFM/CFM\",\n",
    "        \"COSMETRIX\": \"COSMETRIX\",\n",
    "        \"COVER GIRL\": \"COVER GIRL\",\n",
    "        \"DIAL\": \"DIAL\",\n",
    "        \"DOVE\": \"DOVE\",\n",
    "        \"DYCLASS\": \"DYCLASS\",\n",
    "        \"ECAR\": \"ECAR\",\n",
    "        \"EL EXITO\": \"EL EXITO\",\n",
    "        \"ELIZABETH ARDEN\": \"ELIZABETH ARDEN\",\n",
    "        \"ESSENCE\": \"ESSENCE\",\n",
    "        \"FAMILIA\": \"FAMILIA\",\n",
    "        \"FEBREZE\": \"FEBREZE\",\n",
    "        \"FISA\": \"FISA\",\n",
    "        \"HASK\": \"HASK\",\n",
    "        \"HENKEL\": \"HENKEL\",\n",
    "        \"HERBAL ESSENCES\": \"HERBAL ESSENCES\",\n",
    "        \"IMPORTADOS PROCTER\": \"IMPORTADOS PROCTER\",\n",
    "        \"JERONIMO MARTINS\": \"JERONIMO MARTINS\",\n",
    "        \"KANABECARE\": \"KANABECARE\",\n",
    "        \"KIMBERLY\": \"KIMBERLY\",\n",
    "        \"KOBA\": \"D1\",\n",
    "        \"L&G ASOCIADOS\": \"L&G ASOCIADOS\",\n",
    "        \"LA POPULAR\": \"LA POPULAR\",\n",
    "        \"LEONISA\": \"LEONISA\",\n",
    "        \"LOCATEL\": \"LOCATEL\",\n",
    "        \"LOREAL\": \"LOREAL\",\n",
    "        \"LOVE, BEAUTY AND PLANET\": \"LOVE, BEAUTY AND PLANET\",\n",
    "        \"MAUI\": \"MAUI\",\n",
    "        \"MAX FACTOR\": \"MAX FACTOR\",\n",
    "        \"MAX FACTOR EXPORTACI√ìN\": \"MAX FACTOR\",\n",
    "        \"MAX FACTOR GLOBAL\": \"MAX FACTOR\",\n",
    "        \"MF COL + EXP\": \"MAX FACTOR\",\n",
    "        \"MF GLOBAL\": \"MAX FACTOR\",\n",
    "        \"MILAGROS\": \"MILAGROS\",\n",
    "        \"MONCLER\": \"MONCLER\",\n",
    "        \"MORROCCANOIL\": \"MORROCCANOIL\",\n",
    "        \"NATURA\": \"NATURA\",\n",
    "        \"NATURAL PARADISE\": \"NATURAL PARADISE\",\n",
    "        \"NIVEA\": \"NIVEA\",\n",
    "        \"NOPIKEX\": \"NOPIKEX\",\n",
    "        \"NOVAVENTA FPT\": \"NOVAVENTA FPT\",\n",
    "        \"NUDE\": \"NUDE\",\n",
    "        \"OGX\": \"OGX\",\n",
    "        \"OLAY\": \"OLAY\",\n",
    "        \"OMNILIFE\": \"OMNILIFE\",\n",
    "        \"OTRAS\": \"OTRAS\",\n",
    "        \"PREBEL\": \"PREBEL\",\n",
    "        \"QVS\": \"ACCESORIOS\",\n",
    "        \"SALLY HANSEN\": \"SALLY HANSEN\",\n",
    "        \"SIN ASIGNAR\": \"SIN ASIGNAR\",\n",
    "        \"SOLLA\": \"SOLLA\",\n",
    "        \"ST. IVES\": \"ST. IVES\",\n",
    "        \"UBU\": \"ACCESORIOS\",\n",
    "        \"UNILEVER\": \"UNILEVER\",\n",
    "        \"VENTA DIRECTA COSM√âTICOS\": \"VENTA DIRECTA COSM√âTICOS\",\n",
    "        \"VIT√ö\": \"VIT√ö\",\n",
    "        \"VIT√ö  EXPORTACI√ìN\": \"VIT√ö\",\n",
    "        \"WELLA CONSUMO\": \"WELLA CONSUMO\",\n",
    "        \"WELLA PROFESSIONAL\": \"WELLA PROFESSIONAL\",\n",
    "        \"YARDLEY\": \"YARDLEY\",\n",
    "        \"CAT√ÅLOGO DE PRODUCTOS\": \"CAT√ÅLOGO DE PRODUCTOS\",\n",
    "        \"D1\": \"D1\",\n",
    "        \"WORMSER\": \"WORMSER\",\n",
    "        \"PROCTER AND GAMBLE\": \"P&G\",\n",
    "        \"DAVINES\": \"DAVINES\",\n",
    "        \"LA FABRIL\": \"LA FABRIL\",\n",
    "        \"REVOX\": \"REVOX\",\n",
    "        \"TENDENCIAS AB\": \"TENDENCIAS AB\",\n",
    "    }\n",
    "\n",
    "\n",
    "def insert_subsegmentacion() -> Dict[str, str]:\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    RETORNA UN DICCIONARIO CON EL MAPEO DE MARCAS QM A SUBSEGMENTACI√ìN.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"ACCESORIOS\": \"OTROS\",\n",
    "        \"ADIDAS\": \"OTROS\",\n",
    "        \"AGATHA RUIZ DE LA PRADA\": \"OTROS\",\n",
    "        \"ALICORP\": \"FULL\",\n",
    "        \"AMAZON\": \"RETAILERS\",\n",
    "        \"AMWAY\": \"SISTEMA DE VENTAS\",\n",
    "        \"ARDEN FOR MEN\": \"OTROS\",\n",
    "        \"AVON\": \"FULL\",\n",
    "        \"BALANCE\": \"FULL\",\n",
    "        \"BANCO PREBEL\": \"FULL\",\n",
    "        \"BEAUTYHOLICS\": \"OTROS\",\n",
    "        \"BIO OIL\": \"OTROS\",\n",
    "        \"BIOTECNIK\": \"FULL\",\n",
    "        \"BURTS_BEES\": \"OTROS\",\n",
    "        \"CADIVEU\": \"PROFESIONALES\",\n",
    "        \"CALA\": \"FULL\",\n",
    "        \"CATRICE\": \"OTROS\",\n",
    "        \"CONNECT FOR MEN\": \"OTROS\",\n",
    "        \"COSMETRIX\": \"OTROS\",\n",
    "        \"COVER GIRL\": \"OTROS\",\n",
    "        \"DIAL\": \"RETAILERS\",\n",
    "        \"DOVE\": \"OTROS\",\n",
    "        \"DYCLASS\": \"SISTEMA DE VENTAS\",\n",
    "        \"ECAR\": \"FULL\",\n",
    "        \"EL EXITO\": \"RETAILERS\",\n",
    "        \"ELIZABETH ARDEN\": \"OTROS\",\n",
    "        \"ESSENCE\": \"OTROS\",\n",
    "        \"FAMILIA\": \"FULL\",\n",
    "        \"FEBREZE\": \"OTROS\",\n",
    "        \"FISA\": \"FULL\",\n",
    "        \"HASK\": \"OTROS\",\n",
    "        \"HENKEL\": \"FULL\",\n",
    "        \"HERBAL ESSENCES\": \"OTROS\",\n",
    "        \"IMPORTADOS PROCTER\": \"OTROS\",\n",
    "        \"JERONIMO MARTINS\": \"RETAILERS\",\n",
    "        \"KANABECARE\": \"OTROS\",\n",
    "        \"KIMBERLY\": \"FULL\",\n",
    "        \"KOBA\": \"RETAILERS\",\n",
    "        \"L&G ASOCIADOS\": \"FULL\",\n",
    "        \"LA POPULAR\": \"RETAILERS\",\n",
    "        \"LEONISA\": \"SISTEMA DE VENTAS\",\n",
    "        \"LOCATEL\": \"RETAILERS\",\n",
    "        \"LOREAL\": \"FULL\",\n",
    "        \"LOVE, BEAUTY AND PLANET\": \"OTROS\",\n",
    "        \"MAUI\": \"OTROS\",\n",
    "        \"MAX FACTOR\": \"OTROS\",\n",
    "        \"MAX FACTOR EXPORTACI√ìN\": \"OTROS\",\n",
    "        \"MAX FACTOR GLOBAL\": \"OTROS\",\n",
    "        \"MILAGROS\": \"SISTEMA DE VENTAS\",\n",
    "        \"MONCLER\": \"RETAILERS\",\n",
    "        \"MORROCCANOIL\": \"PROFESIONALES\",\n",
    "        \"NATURA\": \"FULL\",\n",
    "        \"NATURAL PARADISE\": \"OTROS\",\n",
    "        \"NIVEA\": \"FULL\",\n",
    "        \"NOPIKEX\": \"OTROS\",\n",
    "        \"NOVAVENTA FPT\": \"SISTEMA DE VENTAS\",\n",
    "        \"NUDE\": \"NUDE\",\n",
    "        \"OGX\": \"OTROS\",\n",
    "        \"OLAY\": \"OTROS\",\n",
    "        \"OMNILIFE\": \"SISTEMA DE VENTAS\",\n",
    "        \"OTRAS\": \"OTROS\",\n",
    "        \"PREBEL\": \"OTROS\",\n",
    "        \"QVS\": \"OTROS\",\n",
    "        \"SALLY HANSEN\": \"OTROS\",\n",
    "        \"SIN ASIGNAR\": \"FULL\",\n",
    "        \"SOLLA\": \"FULL\",\n",
    "        \"ST. IVES\": \"OTROS\",\n",
    "        \"UBU\": \"OTROS\",\n",
    "        \"UNILEVER\": \"TOLL\",\n",
    "        \"VENTA DIRECTA COSM√âTICOS\": \"FULL\",\n",
    "        \"VIT√ö\": \"OTROS\",\n",
    "        \"VIT√ö  EXPORTACI√ìN\": \"OTROS\",\n",
    "        \"WELLA CONSUMO\": \"OTROS\",\n",
    "        \"WELLA PROFESSIONAL\": \"PROFESIONALES\",\n",
    "        \"YARDLEY\": \"OTROS\",\n",
    "        \"D1\": \"RETAILERS\",\n",
    "        \"CAT√ÅLOGO DE PRODUCTOS\": \"RETAILERS\",\n",
    "        \"WORMSER\": \"RETAILERS\",\n",
    "        \"PROCTER AND GAMBLE\": \"FULL\",\n",
    "        \"DAVINES\": \"OTROS\",\n",
    "        \"LA FABRIL\": \"OTROS\",\n",
    "        \"REVOX\": \"OTROS\",\n",
    "        \"TENDENCIAS AB\": \"RETAILERS\"\n",
    "    }\n",
    "\n",
    "\n",
    "def insert_segments() -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Retorna un diccionario con el mapeo de marcas QM a segmentaciones.\n",
    "    \"\"\"\n",
    "    # TODO: Implementar el diccionario de segmentaciones seg√∫n la l√≥gica de negocio\n",
    "    return {\n",
    "        \"OTROS CLIENTES DO\": \"DUE√ëOS DE CANAL\",\n",
    "        \"MARKETING PERSONAL\": \"DUE√ëOS DE CANAL\",\n",
    "        \"OMNILIFE\": \"DUE√ëOS DE CANAL\",\n",
    "        \"JERONIMO MARTINS\": \"DUE√ëOS DE CANAL\",\n",
    "        \"LEONISA\": \"DUE√ëOS DE CANAL\",\n",
    "        \"LOCATEL\": \"DUE√ëOS DE CANAL\",\n",
    "        \"NOVAVENTA\": \"DUE√ëOS DE CANAL\",\n",
    "        \"EL √âXITO\": \"DUE√ëOS DE CANAL\",\n",
    "        \"MILAGROS ENTERPRISE\": \"DUE√ëOS DE CANAL\",\n",
    "        \"LA POPULAR\": \"DUE√ëOS DE CANAL\",\n",
    "        \"D1\": \"DUE√ëOS DE CANAL\",\n",
    "        \"USA\": \"DUE√ëOS DE CANAL\",\n",
    "        \"USA\": \"DUE√ëOS DE CANAL\",\n",
    "        \"EL EXITO\": \"DUE√ëOS DE CANAL\",\n",
    "        \"NOVAVENTA FPT\": \"DUE√ëOS DE CANAL\",\n",
    "        \"MILAGROS\": \"DUE√ëOS DE CANAL\",\n",
    "        \"WORMSER\": \"DUE√ëOS DE CANAL\",\n",
    "        \"TENDENCIAS AB\": \"DUE√ëOS DE CANAL\",\n",
    "        \"LA FABRIL\": \"DUE√ëOS DE CANAL\",\n",
    "        \"UNILEVER\": \"EXPERTOS LOCALES\",\n",
    "        \"NATURA\": \"EXPERTOS LOCALES\",\n",
    "        \"BIOTECNIK\": \"EXPERTOS LOCALES\",\n",
    "        \"NIVEA\": \"EXPERTOS LOCALES\",\n",
    "        \"BRITO\": \"EXPERTOS LOCALES\",\n",
    "        \"AVON\": \"EXPERTOS LOCALES\",\n",
    "        \"OTROS EXPERTOS LOCALES\": \"EXPERTOS LOCALES\",\n",
    "        \"ALICORP\": \"EXPERTOS LOCALES\",\n",
    "        \"SOLLA\": \"EXPERTOS LOCALES\",\n",
    "        \"ECAR\": \"EXPERTOS LOCALES\",\n",
    "        \"FISA\": \"EXPERTOS LOCALES\",\n",
    "        \"KIMBERLY\": \"EXPERTOS LOCALES\",\n",
    "        \"BELCORP\": \"EXPERTOS LOCALES\",\n",
    "        \"AMWAY\": \"EXPERTOS LOCALES\",\n",
    "        \"PROCTER AND GAMBLE\": \"EXPERTOS LOCALES\",\n",
    "        \"HENKEL\": \"EXPERTOS LOCALES\",\n",
    "        \"DIAL\": \"EXPERTOS LOCALES\",\n",
    "        \"BEIERSDORF\": \"EXPERTOS LOCALES\",\n",
    "        \"OTROS EXPERTOS LOCALES\": \"EXPERTOS LOCALES\",\n",
    "        \"FAMILIA\": \"EXPERTOS LOCALES\",\n",
    "        \"BALANCE\": \"EXPERTOS LOCALES\",\n",
    "        \"MAX FACTOR\": \"EXPERTOS NO LOCALES\",\n",
    "        \"DYCLASS\": \"EXPERTOS NO LOCALES\",\n",
    "        \"WELLA CONSUMO\": \"EXPERTOS NO LOCALES\",\n",
    "        \"BIO OIL\": \"EXPERTOS NO LOCALES\",\n",
    "        \"OGX\": \"EXPERTOS NO LOCALES\",\n",
    "        \"COVER GIRL\": \"EXPERTOS NO LOCALES\",\n",
    "        \"WELLA PROFESSIONAL\": \"EXPERTOS NO LOCALES\",\n",
    "        \"ADIDAS\": \"EXPERTOS NO LOCALES\",\n",
    "        \"ACCESORIOS\": \"EXPERTOS NO LOCALES\",\n",
    "        \"BURTS_BEES\": \"EXPERTOS NO LOCALES\",\n",
    "        \"NOPIKEX\": \"EXPERTOS NO LOCALES\",\n",
    "        \"QVS\": \"EXPERTOS NO LOCALES\",\n",
    "        \"UBU\": \"EXPERTOS NO LOCALES\",\n",
    "        \"ESSENCE\": \"EXPERTOS NO LOCALES\",\n",
    "        \"MORROCCANOIL\": \"EXPERTOS NO LOCALES\",\n",
    "        \"HASK\": \"EXPERTOS NO LOCALES\",\n",
    "        \"HERBAL ESSENCES\": \"EXPERTOS NO LOCALES\",\n",
    "        \"LOVE, BEAUTY AND PLANET\": \"EXPERTOS NO LOCALES\",\n",
    "        \"CATRICE\": \"EXPERTOS NO LOCALES\",\n",
    "        \"NATURAL PARADISE\": \"EXPERTOS NO LOCALES\",\n",
    "        \"OLAY\": \"EXPERTOS NO LOCALES\",\n",
    "        \"MID\": \"EXPERTOS NO LOCALES\",\n",
    "        \"SECRET\": \"EXPERTOS NO LOCALES\",\n",
    "        \"FEBREZE\": \"EXPERTOS NO LOCALES\",\n",
    "        \"TAMPAX\": \"EXPERTOS NO LOCALES\",\n",
    "        \"OFCORSS C.I HERMECO\": \"EXPERTOS NO LOCALES\",\n",
    "        \"CADIVEU\": \"EXPERTOS NO LOCALES\",\n",
    "        \"MAX FACTOR GLOBAL\": \"EXPERTOS NO LOCALES\",\n",
    "        \"SEBASTIAN\": \"EXPERTOS NO LOCALES\",\n",
    "        \"AFFRESH\": \"EXPERTOS NO LOCALES\",\n",
    "        \"COSMETRIX\": \"EXPERTOS NO LOCALES\",\n",
    "        \"INCENTIVOS MAX FACTOR\": \"EXPERTOS NO LOCALES\",\n",
    "        \"OTROS EXPERTOS NO LOCALES\": \"EXPERTOS NO LOCALES\",\n",
    "        \"DAVINES\": \"EXPERTOS NO LOCALES\",\n",
    "        \"P&G\": \"EXPERTOS NO LOCALES\",\n",
    "        \"REVOX\": \"EXPERTOS NO LOCALES\",\n",
    "        \"UTOPICK\": \"EXPERTOS NO LOCALES\",\n",
    "        \"IMPORTADOS PROCTER\": \"EXPERTOS NO LOCALES\",\n",
    "        \"ST. IVES\": \"EXPERTOS NO LOCALES\",\n",
    "        \"ARDEN FOR MEN\": \"MARCAS PROPIAS\",\n",
    "        \"NUDE\": \"MARCAS PROPIAS\",\n",
    "        \"ELIZABETH ARDEN\": \"MARCAS PROPIAS\",\n",
    "        \"YARDLEY\": \"MARCAS PROPIAS\",\n",
    "        \"VIT√ö\": \"MARCAS PROPIAS\",\n",
    "        \"PREBEL\": \"MARCAS PROPIAS\",\n",
    "        \"OTRAS MP\": \"MARCAS PROPIAS\",\n",
    "        \"AFM/CFM\": \"MARCAS PROPIAS\",\n",
    "        \"BODY CLEAR\": \"NO APLICA\",\n",
    "        \"OTRAS\": \"NO APLICA\",\n",
    "        \"GILLETTE\": \"NO APLICA\",\n",
    "        \"L&G ASOCIADOS\": \"NO APLICA\",\n",
    "        \"CAT√ÅLOGO DE PRODUCTOS\": \"NO APLICA\",\n",
    "        \"HINODE\": \"NO APLICA\",\n",
    "        \"PFIZER\": \"NO APLICA\",\n",
    "        \"CONTEXPORT DISNEY\": \"NO APLICA\",\n",
    "        \"SYSTEM PROFESSIONAL\": \"NO APLICA\",\n",
    "        \"WELONDA\": \"NO APLICA\",\n",
    "        \"SIN ASIGNAR\": \"NO APLICA\",\n",
    "        \"CAT√ÅLOGO DE PRODUCTOS\": \"NO APLICA\",\n",
    "    }\n",
    "\n",
    "\n",
    "def calculate_rango_permanencia(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Calcula el rango de permanencia basado en las condiciones especificadas.\n",
    "\n",
    "    Args:\n",
    "        row: Fila del DataFrame con las columnas necesarias\n",
    "\n",
    "    Returns:\n",
    "        str: Rango de permanencia calculado\n",
    "    \"\"\"\n",
    "    lote = row.get(\"LOTE\", None)\n",
    "    permanencia = row.get(\"PERMANENCIA\", None)\n",
    "    rango_permanencia = row.get(\"RANGO DE PERMANENCIA\", None)\n",
    "\n",
    "    if lote == \"222222\":\n",
    "        return \"1.MENOR DE 90 DIAS\"\n",
    "    elif permanencia == 0 and rango_permanencia == \"5.MAYOR O IGUAL A 360 DIAS\":\n",
    "        return \"5.ENTRE 360 Y 540 DIAS\"\n",
    "    elif rango_permanencia == \"5.MAYOR O IGUAL A 360 DIAS\":\n",
    "        if permanencia < 540:\n",
    "            return \"5.ENTRE 360 Y 540 DIAS\"\n",
    "        elif permanencia < 720:\n",
    "            return \"6.ENTRE 540 Y 720 DIAS\"\n",
    "        else:\n",
    "            return \"7.MAYOR DE 720 DIAS\"\n",
    "    else:\n",
    "        return rango_permanencia\n",
    "\n",
    "\n",
    "def calculate_status_cons(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Calcula el estado de consumo basado en las condiciones de vencimiento, bloqueo y obsolescencia.\n",
    "\n",
    "    Args:\n",
    "        row: Fila del DataFrame con las columnas necesarias\n",
    "\n",
    "    Returns:\n",
    "        str: Estado calculado (VENCIDO, BLOQUEADO, OBSOLETO, PAV o DISPONIBLE)\n",
    "    \"\"\"\n",
    "    rango_prox_vencer = row.get(\"RANGO PR√ìX.VENCER MM\")\n",
    "    valor_BLOQUEADO = row.get(\"VALOR BLOQUEADO MM\")\n",
    "    valor_OBSOLETO = row.get(\"VALOR OBSOLETO\")\n",
    "\n",
    "    if rango_prox_vencer == \"VENCIDO\":\n",
    "        return \"VENCIDO\"\n",
    "    elif valor_BLOQUEADO != 0:\n",
    "        return \"BLOQUEADO\"\n",
    "    elif valor_OBSOLETO != 0:\n",
    "        return \"OBSOLETO\"\n",
    "    elif rango_prox_vencer in [\"1.PAV 3 MESES\", \"2.PAV 4 A 6 MESES\"]:\n",
    "        return \"PAV\"\n",
    "    else:\n",
    "        return \"DISPONIBLE\"\n",
    "\n",
    "\n",
    "def calculate_valor_def(row: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Calcula el valor definitivo basado en el estado de consumo.\n",
    "\n",
    "    Args:\n",
    "        row: Fila del DataFrame con las columnas necesarias\n",
    "\n",
    "    Returns:\n",
    "        float: Valor definitivo calculado\n",
    "    \"\"\"\n",
    "    status_cons = row.get(\"STATUS CONS\")\n",
    "    valor_BLOQUEADO = row.get(\"VALOR BLOQUEADO MM\")\n",
    "    valor_total = row.get(\"VALOR TOTAL MM\")\n",
    "\n",
    "    return valor_BLOQUEADO if status_cons == \"BLOQUEADO\" else valor_total\n",
    "\n",
    "\n",
    "def calculate_rango_obsolescencia(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Calcula el rango de obsolescencia basado en las fechas de entrada y obsolescencia.\n",
    "\n",
    "    Args:\n",
    "        row: Fila del DataFrame con las columnas necesarias\n",
    "\n",
    "    Returns:\n",
    "        str: Rango de obsolescencia calculado\n",
    "    \"\"\"\n",
    "    status_cons = row.get(\"STATUS CONS\")\n",
    "    fecha_entrada = row.get(\"FECHA ENTRADA\")\n",
    "    fecha_OBSOLETO = row.get(\"FECHA OBSOLETO\")\n",
    "\n",
    "    if status_cons != \"OBSOLETO\" or pd.isna(fecha_entrada) or pd.isna(fecha_OBSOLETO):\n",
    "        return \"FALSO\"\n",
    "\n",
    "    dias_obsolescencia = (fecha_entrada - fecha_OBSOLETO).days\n",
    "\n",
    "    if dias_obsolescencia <= 90:\n",
    "        return \"1.MENOR DE 90 DIAS\"\n",
    "    elif 90 < dias_obsolescencia <= 180:\n",
    "        return \"2.ENTRE 90 Y 180 DIAS\"\n",
    "    elif 180 < dias_obsolescencia <= 270:\n",
    "        return \"3.ENTRE 180 Y 270 DIAS\"\n",
    "    elif 270 < dias_obsolescencia <= 360:\n",
    "        return \"4.ENTRE 270 Y 360 DIAS\"\n",
    "    elif 360 < dias_obsolescencia <= 540:\n",
    "        return \"5.ENTRE 360 Y 540 DIAS\"\n",
    "    elif 540 < dias_obsolescencia <= 720:\n",
    "        return \"6.ENTRE 540 Y 720 DIAS\"\n",
    "    else:\n",
    "        return \"7.MAYOR DE 720 DIAS\"\n",
    "\n",
    "\n",
    "def calculate_rango_vencido(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Calcula el rango de vencimiento basado en las fechas de entrada y caducidad.\n",
    "\n",
    "    Args:\n",
    "        row: Fila del DataFrame con las columnas necesarias\n",
    "\n",
    "    Returns:\n",
    "        str: Rango de vencimiento calculado\n",
    "    \"\"\"\n",
    "    status_cons = row.get(\"STATUS CONS\")\n",
    "    fecha_entrada = row.get(\"FECHA ENTRADA\")\n",
    "    fecha_caducidad = row.get(\"FECH, CADUCIDAD/FECH PREF. CONSUMO\")\n",
    "\n",
    "    if status_cons != \"VENCIDO\" or pd.isna(fecha_entrada) or pd.isna(fecha_caducidad):\n",
    "        return \"FALSO\"\n",
    "\n",
    "    dias_vencido = (fecha_entrada - fecha_caducidad).days\n",
    "\n",
    "    if dias_vencido <= 90:\n",
    "        return \"1.MENOR DE 90 DIAS\"\n",
    "    elif 90 < dias_vencido <= 180:\n",
    "        return \"2.ENTRE 90 Y 180 DIAS\"\n",
    "    elif 180 < dias_vencido <= 270:\n",
    "        return \"3.ENTRE 180 Y 270 DIAS\"\n",
    "    elif 270 < dias_vencido <= 360:\n",
    "        return \"4.ENTRE 270 Y 360 DIAS\"\n",
    "    elif 360 < dias_vencido <= 540:\n",
    "        return \"5.ENTRE 360 Y 540 DIAS\"\n",
    "    elif 540 < dias_vencido <= 720:\n",
    "        return \"6.ENTRE 540 Y 720 DIAS\"\n",
    "    else:\n",
    "        return \"7.MAYOR DE 720 DIAS\"\n",
    "\n",
    "\n",
    "def calculate_rango_bloqueado(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Calcula el rango de bloqueo basado en las fechas de entrada y bloqueo.\n",
    "\n",
    "    Args:\n",
    "        row: Fila del DataFrame con las columnas necesarias\n",
    "\n",
    "    Returns:\n",
    "        str: Rango de bloqueo calculado\n",
    "    \"\"\"\n",
    "    status_cons = row.get(\"STATUS CONS\")\n",
    "    fecha_entrada = row.get(\"FECHA ENTRADA\")\n",
    "    fecha_bloqueado = row.get(\"FECHA BLOQUEADO\")\n",
    "\n",
    "    if status_cons != \"BLOQUEADO\" or pd.isna(fecha_entrada) or pd.isna(fecha_bloqueado):\n",
    "        return \"FALSO\"\n",
    "\n",
    "    dias_vencido = (fecha_entrada - fecha_bloqueado).days\n",
    "\n",
    "    if dias_vencido <= 90:\n",
    "        return \"1.MENOR DE 90 DIAS\"\n",
    "    elif 90 < dias_vencido <= 180:\n",
    "        return \"2.ENTRE 90 Y 180 DIAS\"\n",
    "    elif 180 < dias_vencido <= 270:\n",
    "        return \"3.ENTRE 180 Y 270 DIAS\"\n",
    "    elif 270 < dias_vencido <= 360:\n",
    "        return \"4.ENTRE 270 Y 360 DIAS\"\n",
    "    elif 360 < dias_vencido <= 540:\n",
    "        return \"5.ENTRE 360 Y 540 DIAS\"\n",
    "    elif 540 < dias_vencido <= 720:\n",
    "        return \"6.ENTRE 540 Y 720 DIAS\"\n",
    "    else:\n",
    "        return \"7.MAYOR A 720 DIAS\"\n",
    "\n",
    "\n",
    "def calculate_tiempo_bloqueo(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Calcula el tiempo de bloqueo basado en las fechas de entrada y bloqueo.\n",
    "\n",
    "    Args:\n",
    "        row: Fila del DataFrame con las columnas necesarias\n",
    "\n",
    "    Returns:\n",
    "        str: Tiempo de bloqueo calculado\n",
    "    \"\"\"\n",
    "    fecha_entrada = row.get(\"FECHA ENTRADA\")\n",
    "    fecha_bloqueado = row.get(\"FECHA BLOQUEADO\")\n",
    "    \n",
    "    if pd.isna(fecha_entrada) or pd.isna(fecha_bloqueado):\n",
    "        return 0\n",
    "\n",
    "    tiempo_bloqueado = (fecha_entrada - fecha_bloqueado).days\n",
    "    \n",
    "    return tiempo_bloqueado    \n",
    "\n",
    "\n",
    "def calculate_rango_cons(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Calcula el rango de consumo final basado en el status y los rangos correspondientes.\n",
    "\n",
    "    Args:\n",
    "        row: Fila del DataFrame con las columnas necesarias\n",
    "\n",
    "    Returns:\n",
    "        str: Rango de consumo calculado\n",
    "    \"\"\"\n",
    "    status = row.get(\"STATUS CONS\")\n",
    "\n",
    "    if status == \"OBSOLETO\":\n",
    "        return row.get(\"RANGO OBSOLESCENCIA\")\n",
    "    elif status == \"VENCIDO\":\n",
    "        return row.get(\"RANGO VENCIDO 2\")\n",
    "    elif status == \"BLOQUEADO\":\n",
    "        return row.get(\"RANGO BLOQUEADO 2\")\n",
    "    elif status == \"PAV\":\n",
    "        return row.get(\"RANGO DE PERMANENCIA 2\")\n",
    "    else:\n",
    "        return row.get(\"RANGO DE PERMANENCIA 2\")\n",
    "\n",
    "\n",
    "def calculate_avon_natura_factor_and_class(row, lookup_dict):\n",
    "    \"\"\"\n",
    "    Calcula factor provisional y clasificaci√≥n solo para materiales de AVON y NATURA,\n",
    "    siguiendo la l√≥gica de la f√≥rmula de Excel proporcionada.\n",
    "    \"\"\"\n",
    "    seg        = row[\"SEGMENTACION\"]\n",
    "    status     = row[\"STATUS CONS\"]\n",
    "    tiempo     = row[\"TIEMPO BLOQUEADO\"]\n",
    "    perm       = row[\"PERMANENCIA\"]\n",
    "    tipo_mat   = row[\"TIPO DE MATERIAL (I)\"]\n",
    "    negocio    = row[\"NEGOCIO INVENTARIOS\"]\n",
    "    rango_cons = str(row[\"RANGO CONS\"]).strip()\n",
    "    indic      = row[\"INDICADOR STOCK ESPEC.\"]\n",
    "\n",
    "    # 1) Segmento interno bloqueado poco tiempo\n",
    "    if seg in [\"MARCAS PROPIAS\", \"EXPERTOS NO LOCALES\", \"DUE√ëOS DE DEMANDA\"] \\\n",
    "       and status == \"BLOQUEADO\" and tiempo <= 30:\n",
    "        return 0.0, \"BAJO\"\n",
    "\n",
    "    # 2) Disponible o PAV y permanencia <= 30 en granel\n",
    "    if status in [\"DISPONIBLE\", \"PAV\"] \\\n",
    "       and perm <= 30 \\\n",
    "       and tipo_mat in [\"GRANEL FAB A TERCERO\", \"GRANEL\"]:\n",
    "        return 0.0, \"BAJO\"\n",
    "\n",
    "    # 3) Negocio FPT ‚Üí lookup con A2&AQ2&AV2\n",
    "    if negocio == \"FPT\":\n",
    "        key = f\"{negocio}{status}{rango_cons}\"\n",
    "        return lookup_dict.get(key, (0.0, \"BAJO\"))\n",
    "\n",
    "    # 4) Stock ‚â† W y obsoleto/bloqueado/vencido ‚Üí mismo lookup\n",
    "    if indic != \"W\" and status in [\"OBSOLETO\", \"BLOQUEADO\", \"VENCIDO\"]:\n",
    "        key = f\"{negocio}{status}{rango_cons}\"\n",
    "        return lookup_dict.get(key, (0.0, \"BAJO\"))\n",
    "\n",
    "    # 5) Stock ‚â† W y disponible ‚Üí lookup con cobertura+permanencia2\n",
    "    if indic != \"W\" and status == \"DISPONIBLE\":\n",
    "        key = (\n",
    "            str(row[\"RANGO COBERTURA\"]).strip()\n",
    "            + str(row[\"RANGO DE PERMANENCIA 2\"]).strip()\n",
    "        )\n",
    "        return lookup_dict.get(key, (0.0, \"BAJO\"))\n",
    "\n",
    "    # 6) Marca Avon/Natura y estado vencido/obsoleto/PAV ‚Üí primer d√≠gito\n",
    "    marca_qm = row[\"MARCA DE QM\"]\n",
    "    if marca_qm in [\"AVON\", \"NATURA\"] and status in [\"VENCIDO\", \"OBSOLETO\", \"PAV\"]:\n",
    "        try:\n",
    "            first_digit = int(rango_cons[0])\n",
    "            return (1.0, \"MUY ALTO\") if first_digit > 4 else (0.2, \"MEDIO\")\n",
    "        except:\n",
    "            return 0.0, \"BAJO\"\n",
    "\n",
    "    # Default\n",
    "    return 0.0, \"BAJO\"\n",
    "\n",
    "\n",
    "def calculate_base_riesgo_column(row: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Calcula el valor de la columna de base riesgo\n",
    "    \"\"\"\n",
    "    if row[\"CLAS BASE RIESGO\"] == \"BAJO\":\n",
    "        return 0.0\n",
    "    else:\n",
    "        return row[\"VALOR DEF\"]\n",
    "\n",
    "\n",
    "def calculate_provision_column(row: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Calcula el valor de la columna de provisi√≥n\n",
    "    \"\"\"\n",
    "    if row[\"MARCA DE QM\"] == \"OTRAS\":\n",
    "        return 0.0\n",
    "    else:\n",
    "        return row[\"VALOR DEF\"] * row['FACTOR PROV']\n",
    "\n",
    "\n",
    "def process_dataframe_avon_natura(df_avon_natura: pd.DataFrame,df_matrices_avon_natura: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Procesa el DataFrame aplicando todas las reglas de negocio en el orden espec√≠fico requerido.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame con los datos de SAP\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame procesado con todas las columnas calculadas\n",
    "    \"\"\"\n",
    "    # 1. A√±adir columnas formuladas de 'MARCA CONCAT' y 'SEGMENTACION'\n",
    "    df_avon_natura[\"MARCA CONCAT\"] = df_avon_natura[\"MARCA DE QM\"].apply(lambda x: insert_marks().get(x, \"\"))\n",
    "    df_avon_natura[\"SEGMENTACION\"] = df_avon_natura[\"MARCA DE QM\"].apply(\n",
    "        lambda x: insert_segments().get(x, \"OTRAS\")\n",
    "    )\n",
    "    df_avon_natura[\"SUBSEGMENTACION\"] = df_avon_natura[\"MARCA DE QM\"].apply(\n",
    "        lambda x: insert_subsegmentacion().get(x, \"\")\n",
    "    )\n",
    "\n",
    "    # 2. Calcular 'RANGO DE PERMANENCIA 2'\n",
    "    required_columns = {\"LOTE\", \"PERMANENCIA\", \"RANGO DE PERMANENCIA\"}\n",
    "    if required_columns.issubset(df_avon_natura.columns):\n",
    "        df_avon_natura[\"RANGO DE PERMANENCIA 2\"] = df_avon_natura.apply(calculate_rango_permanencia, axis=1)\n",
    "    else:\n",
    "        print(f\"Faltan columnas: {required_columns - set(df_avon_natura.columns)}\")\n",
    "\n",
    "    # 3. Calcular 'STATUS CONS'\n",
    "    required_columns = {\"RANGO PR√ìX.VENCER MM\", \"VALOR BLOQUEADO MM\", \"VALOR OBSOLETO\"}\n",
    "    if required_columns.issubset(df_avon_natura.columns):\n",
    "        df_avon_natura[\"STATUS CONS\"] = df_avon_natura.apply(calculate_status_cons, axis=1)\n",
    "    else:\n",
    "        print(f\"Faltan columnas: {required_columns - set(df_avon_natura.columns)}\")\n",
    "\n",
    "    # 4. Calcular 'VALOR DEF'\n",
    "    required_columns = {\"STATUS CONS\", \"VALOR BLOQUEADO MM\", \"VALOR TOTAL MM\"}\n",
    "    if required_columns.issubset(df_avon_natura.columns):\n",
    "        df_avon_natura[\"VALOR DEF\"] = df_avon_natura.apply(calculate_valor_def, axis=1)\n",
    "    else:\n",
    "        print(f\"Faltan columnas: {required_columns - set(df_avon_natura.columns)}\")\n",
    "\n",
    "    # 5. Reemplazar valores inv√°lidos\n",
    "    df_avon_natura.replace(\"#\", np.nan, inplace=True)\n",
    "\n",
    "    # 6. Convertir columnas de fecha\n",
    "    date_columns = [\n",
    "        \"FECHA ENTRADA\",\n",
    "        \"FECHA OBSOLETO\",\n",
    "        \"FECHA BLOQUEADO\",\n",
    "        \"FECH. FABRICACI√ìN\",\n",
    "        \"CREADO EL\",\n",
    "        \"FECH, CADUCIDAD/FECH PREF. CONSUMO\",\n",
    "    ]\n",
    "\n",
    "    for col in date_columns:\n",
    "        if col in df_avon_natura.columns:\n",
    "            df_avon_natura[col] = pd.to_datetime(df_avon_natura[col], format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "\n",
    "    # 7. Calcular 'RANGO OBSOLESCENCIA'\n",
    "    df_avon_natura[\"RANGO OBSOLESCENCIA\"] = df_avon_natura.apply(calculate_rango_obsolescencia, axis=1)\n",
    "\n",
    "    # 8. Calcular 'RANGO VENCIDO 2'\n",
    "    df_avon_natura[\"RANGO VENCIDO 2\"] = df_avon_natura.apply(calculate_rango_vencido, axis=1)\n",
    "\n",
    "    # 9. Calcular 'RANGO BLOQUEADO 2'\n",
    "    df_avon_natura[\"RANGO BLOQUEADO 2\"] = df_avon_natura.apply(calculate_rango_bloqueado, axis=1)\n",
    "\n",
    "    # 10. Calcular 'RANGO CONS'\n",
    "    df_avon_natura[\"RANGO CONS\"] = df_avon_natura.apply(calculate_rango_cons, axis=1)\n",
    "    \n",
    "    # 11. Calcular 'TIEMPO BLOQUEO'\n",
    "    df_avon_natura[\"TIEMPO BLOQUEADO\"] = df_avon_natura.apply(calculate_tiempo_bloqueo, axis=1)\n",
    "\n",
    "    # Construir lookup_dict **una vez** antes del apply\n",
    "    lookup_dict = {\n",
    "        str(r[\"concatenado\"]).strip(): (r[\"factor_prov\"], r[\"clasificacion\"])\n",
    "        for _, r in df_matrices_avon_natura.iterrows()\n",
    "    }\n",
    "\n",
    "    # Aplicar fila a fila y asignar dos nuevas columnas\n",
    "    df_avon_natura[[\"FACTOR PROV\", \"CLAS BASE RIESGO\"]] = df_avon_natura.apply(\n",
    "        lambda row: pd.Series(calculate_avon_natura_factor_and_class(row, lookup_dict)),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # 13. BASE RIESGO\n",
    "    df_avon_natura[\"BASE RIESGO\"] = df_avon_natura.apply(\n",
    "        calculate_base_riesgo_column, axis=1\n",
    "    )\n",
    "    # 14. PROVISION\n",
    "    df_avon_natura[\"PROVISION\"] = df_avon_natura.apply(\n",
    "        calculate_provision_column, axis=1\n",
    "    )\n",
    "\n",
    "    return df_avon_natura\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_avon_natura = process_dataframe_avon_natura(df_avon_natura, df_matrices_avon_natura)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L√≥gica para el resto de marcas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lookup_dict_by_tipo(\n",
    "    tipo_busqueda: str,\n",
    "    lookup_dict: Dict[str, Tuple[float, str]]\n",
    ") -> Tuple[float, str]:\n",
    "    \"\"\"\n",
    "    Busca en el lookup_dict la primera fila cuya 'tipo_matriz' coincide con tipo_busqueda.\n",
    "    El lookup_dict deber√° mapear tambi√©n tipo_matriz ‚Üí (factor, clasif).\n",
    "    \"\"\"\n",
    "    return lookup_dict.get(tipo_busqueda, (0.0, \"BAJO\"))\n",
    "\n",
    "\n",
    "def calculate_otros_marcas_factor_and_class(\n",
    "    row: pd.Series,\n",
    "    df_matrices_otros_tipos: pd.DataFrame\n",
    ") -> Tuple[float, str]:\n",
    "    \n",
    "    # Extraer campos\n",
    "    seg         = row[\"SEGMENTACION\"].strip()\n",
    "    subseg      = row.get(\"SUBSEGMENTACION\", \"\").strip()\n",
    "    status      = row[\"STATUS CONS\"].strip()\n",
    "    tiempo      = row[\"TIEMPO BLOQUEADO\"]\n",
    "    indic       = row[\"INDICADOR STOCK ESPEC.\"].strip()\n",
    "    tipo_mat    = row[\"TIPO DE MATERIAL (I)\"]\n",
    "    perm        = row[\"PERMANENCIA\"]\n",
    "    rango_cons  = str(row[\"RANGO CONS\"]).strip()\n",
    "    cobertura   = str(row[\"RANGO COBERTURA\"]).strip()\n",
    "    prox_vencer = str(row.get(\"RANGO PR√ìX.VENCER MM\", \"\")).strip()\n",
    "\n",
    "    # 1) Due√±os de canal / Marcas propias / Expertos no locales + Bloqueado corto ‚Üí 0%, BAJO\n",
    "    if seg in [\"DUE√ëOS DE CANAL\", \"MARCAS PROPIAS\", \"EXPERTOS NO LOCALES\"] \\\n",
    "        and status == \"BLOQUEADO\" \\\n",
    "        and tiempo <= 30:                             \n",
    "        return 0.0, \"BAJO\"\n",
    "\n",
    "    # 2) Indicador stock = \"K\" ‚Üí 0%, BAJO\n",
    "    if indic == \"K\":\n",
    "        return 0.0, \"BAJO\"\n",
    "\n",
    "    # 3) Disponible/PAV + Granel y permanencia corta ‚Üí 0%, BAJO\n",
    "    if status in [\"DISPONIBLE\", \"PAV\"] \\\n",
    "        and tipo_mat in [\"GRANEL\", \"GRANEL FAB A TERCERO\"] \\\n",
    "        and perm <= 30:\n",
    "        return 0.0, \"BAJO\"\n",
    "\n",
    "    # 4) Marca \"OTRAS\" o (Disponible + cobertura vac√≠a) ‚Üí 0%, BAJO\n",
    "    if row[\"MARCA DE QM\"] == \"OTRAS\" \\\n",
    "        or (status == \"DISPONIBLE\" and cobertura == \"\"):\n",
    "        return 0.0, \"BAJO\"\n",
    "\n",
    "    # 5) STOCK = \"W\" ‚Üí lookup por tipo de matriz espec√≠fico\n",
    "    if indic == \"W\":\n",
    "        if status in [\"VENCIDO\", \"PAV\"]:\n",
    "            clave = seg + status + rango_cons\n",
    "            tipo_busqueda = 'PVA Y VENCIDOS'\n",
    "        elif status == \"DISPONIBLE\":\n",
    "            clave = seg + cobertura + row[\"RANGO DE PERMANENCIA 2\"]\n",
    "            tipo_busqueda = 'MATRIZ DISPONIBLES VMI'\n",
    "        else:\n",
    "            clave = seg + status + rango_cons\n",
    "            tipo_busqueda = 'OBSOLETO'\n",
    "            \n",
    "        mat = df_matrices_otros_tipos.loc[\n",
    "            (df_matrices_otros_tipos[\"tipo_matriz\"] == tipo_busqueda) &\n",
    "            (df_matrices_otros_tipos[\"concatenado\"].str.strip() == clave)\n",
    "        ]\n",
    "        \n",
    "        if not mat.empty:\n",
    "            return float(mat.iloc[0][\"factor_prov\"]), mat.iloc[0][\"clasificacion\"]\n",
    "        return 0.0, \"BAJO\"\n",
    "\n",
    "    # 6) STOCK = \"SIN ASIGNAR\" u \"O\" ‚Üí m√∫ltiples BUSCARV con fallback\n",
    "    if indic in [\"SIN ASIGNAR\",\"O\"]:\n",
    "        # a) PAV + 1.PAV 3 MESES ‚Üí BUSCARV(AP2&AQ2&W2&AR2; N:R; 4; 0)\n",
    "        if status==\"PAV\" and prox_vencer==\"1.PAV 3 MESES\":\n",
    "            clave = seg + subseg + cobertura + row[\"RANGO DE PERMANENCIA 2\"]\n",
    "            tipo  = \"PVA 1 A 3 MESES\"\n",
    "            mat = df_matrices_otros_tipos.loc[\n",
    "                (df_matrices_otros_tipos[\"tipo_matriz\"] == tipo) &\n",
    "                (df_matrices_otros_tipos[\"concatenado\"].str.strip() == clave)\n",
    "            ]\n",
    "            if not mat.empty:\n",
    "                return float(mat.iloc[0][\"factor_prov\"]), mat.iloc[0][\"clasificacion\"]\n",
    "            \n",
    "        # b) PAV + 2.PAV 4 A 6 MESES ‚Üí BUSCARV(AP2&AQ2&W2&AR2; T:X; 4; 0)\n",
    "        if status==\"PAV\" and prox_vencer==\"2.PAV 4 A 6 MESES\":\n",
    "            clave = seg + subseg + cobertura + row[\"RANGO DE PERMANENCIA 2\"]\n",
    "            tipo  = \"PVA 4 A 6 MESES\"\n",
    "            mat = df_matrices_otros_tipos.loc[\n",
    "                (df_matrices_otros_tipos[\"tipo_matriz\"] == tipo) &\n",
    "                (df_matrices_otros_tipos[\"concatenado\"].str.strip() == clave)\n",
    "            ]\n",
    "            if not mat.empty:\n",
    "                return float(mat.iloc[0][\"factor_prov\"]), mat.iloc[0][\"clasificacion\"]\n",
    "\n",
    "        # c) Disponible ‚Üí primer BUSCARV(AP2&AQ2&W2&AR2; H:L), si falla BUSCARV($AP2&$AQ2&$AS2&\" \"&$AX2; B:F)\n",
    "        if status == \"DISPONIBLE\":\n",
    "            # 1er intento sobre H:L\n",
    "            clave1 = seg + subseg + cobertura + row[\"RANGO DE PERMANENCIA 2\"]\n",
    "            mat1 = df_matrices_otros_tipos.loc[\n",
    "                (df_matrices_otros_tipos[\"tipo_matriz\"] == \"DISPONIBLE\") &\n",
    "                (df_matrices_otros_tipos[\"concatenado\"].str.strip() == clave1)\n",
    "            ]\n",
    "            if not mat1.empty:\n",
    "                return float(mat1.iloc[0][\"factor_prov\"]), mat1.iloc[0][\"clasificacion\"]\n",
    "            # fallback sobre B:F (note el espacio antes de rango_cons)\n",
    "            clave2 = seg + subseg + status + \" \" + rango_cons\n",
    "            mat2 = df_matrices_otros_tipos.loc[\n",
    "                (df_matrices_otros_tipos[\"tipo_matriz\"] == \"OBSOLETOS, BLOQUEADOS, VENCIDOS\") &\n",
    "                (df_matrices_otros_tipos[\"concatenado\"].str.strip() == clave2)\n",
    "            ]\n",
    "            if not mat2.empty:\n",
    "                return float(mat2.iloc[0][\"factor_prov\"]), mat2.iloc[0][\"clasificacion\"]\n",
    "            return 0.0, \"BAJO\"\n",
    "\n",
    "        # d) Obsoleto/Vencido/Bloqueado ‚Üí BUSCARV($AP2&$AQ2&$AS2&\" \"&$AX2; B:F;4;0)\n",
    "        if status in [\"OBSOLETO\",\"VENCIDO\",\"BLOQUEADO\"]:\n",
    "            clave = seg + subseg + status + \" \" + rango_cons\n",
    "            mat = df_matrices_otros_tipos.loc[\n",
    "                (df_matrices_otros_tipos[\"tipo_matriz\"] == \"OBSOLETOS, BLOQUEADOS, VENCIDOS\") &\n",
    "                (df_matrices_otros_tipos[\"concatenado\"].str.strip() == clave)\n",
    "            ]\n",
    "            if not mat.empty:\n",
    "                return float(mat.iloc[0][\"factor_prov\"]), mat.iloc[0][\"clasificacion\"]\n",
    "\n",
    "    # 7) Fallback por defecto ‚Üí 0%, BAJO\n",
    "    return 0.0, \"BAJO\"\n",
    "\n",
    "\n",
    "def process_dataframe_otras_marcas(df_otras_marcas: pd.DataFrame,df_matrices_otros_tipos: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Procesa el DataFrame aplicando todas las reglas de negocio en el orden espec√≠fico requerido.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame con los datos de SAP\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame procesado con todas las columnas calculadas\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. A√±adir columnas formuladas de 'MARCA CONCAT' y 'SEGMENTACION'\n",
    "    df_otras_marcas[\"MARCA CONCAT\"] = df_otras_marcas[\"MARCA DE QM\"].apply(lambda x: insert_marks().get(x, \"\"))\n",
    "    df_otras_marcas[\"SEGMENTACION\"] = df_otras_marcas[\"MARCA DE QM\"].apply(\n",
    "        lambda x: insert_segments().get(x, \"OTRAS\")\n",
    "    )\n",
    "    df_otras_marcas[\"SUBSEGMENTACION\"] = df_otras_marcas[\"MARCA DE QM\"].apply(\n",
    "        lambda x: insert_subsegmentacion().get(x, \"\")\n",
    "    )\n",
    "\n",
    "    # 2. Calcular 'RANGO DE PERMANENCIA 2'\n",
    "    required_columns = {\"LOTE\", \"PERMANENCIA\", \"RANGO DE PERMANENCIA\"}\n",
    "    if required_columns.issubset(df_otras_marcas.columns):\n",
    "        df_otras_marcas[\"RANGO DE PERMANENCIA 2\"] = df_otras_marcas.apply(calculate_rango_permanencia, axis=1)\n",
    "    else:\n",
    "        print(f\"Faltan columnas: {required_columns - set(df_otras_marcas.columns)}\")\n",
    "\n",
    "    # 3. Calcular 'STATUS CONS'\n",
    "    required_columns = {\"RANGO PR√ìX.VENCER MM\", \"VALOR BLOQUEADO MM\", \"VALOR OBSOLETO\"}\n",
    "    if required_columns.issubset(df_otras_marcas.columns):\n",
    "        df_otras_marcas[\"STATUS CONS\"] = df_otras_marcas.apply(calculate_status_cons, axis=1)\n",
    "    else:\n",
    "        print(f\"Faltan columnas: {required_columns - set(df_otras_marcas.columns)}\")\n",
    "\n",
    "    # 4. Calcular 'VALOR DEF'\n",
    "    required_columns = {\"STATUS CONS\", \"VALOR BLOQUEADO MM\", \"VALOR TOTAL MM\"}\n",
    "    if required_columns.issubset(df_otras_marcas.columns):\n",
    "        df_otras_marcas[\"VALOR DEF\"] = df_otras_marcas.apply(calculate_valor_def, axis=1)\n",
    "    else:\n",
    "        print(f\"Faltan columnas: {required_columns - set(df_otras_marcas.columns)}\")\n",
    "\n",
    "    # 5. Reemplazar valores inv√°lidos\n",
    "    df_otras_marcas.replace(\"#\", np.nan, inplace=True)\n",
    "\n",
    "    # 6. Convertir columnas de fecha\n",
    "    date_columns = [\n",
    "        \"FECHA ENTRADA\",\n",
    "        \"FECHA OBSOLETO\",\n",
    "        \"FECHA BLOQUEADO\",\n",
    "        \"FECH. FABRICACI√ìN\",\n",
    "        \"CREADO EL\",\n",
    "        \"FECH, CADUCIDAD/FECH PREF. CONSUMO\",\n",
    "    ]\n",
    "\n",
    "    for col in date_columns:\n",
    "        if col in df_otras_marcas.columns:\n",
    "            df_otras_marcas[col] = pd.to_datetime(df_otras_marcas[col], format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "\n",
    "    # 7. Calcular 'RANGO OBSOLESCENCIA'\n",
    "    df_otras_marcas[\"RANGO OBSOLESCENCIA\"] = df_otras_marcas.apply(calculate_rango_obsolescencia, axis=1)\n",
    "\n",
    "    # 8. Calcular 'RANGO VENCIDO 2'\n",
    "    df_otras_marcas[\"RANGO VENCIDO 2\"] = df_otras_marcas.apply(calculate_rango_vencido, axis=1)\n",
    "\n",
    "    # 9. Calcular 'RANGO BLOQUEADO 2'\n",
    "    df_otras_marcas[\"RANGO BLOQUEADO 2\"] = df_otras_marcas.apply(calculate_rango_bloqueado, axis=1)\n",
    "\n",
    "    # 10. Calcular 'RANGO CONS'\n",
    "    df_otras_marcas[\"RANGO CONS\"] = df_otras_marcas.apply(calculate_rango_cons, axis=1)\n",
    "    \n",
    "    # 11. Calcular 'TIEMPO BLOQUEO'\n",
    "    df_otras_marcas[\"TIEMPO BLOQUEADO\"] = df_otras_marcas.apply(calculate_tiempo_bloqueo, axis=1)\n",
    "\n",
    "    # 12. Aplicar c√°lculo fila a fila, pasando el DataFrame de matrices:\n",
    "    df_otras_marcas[[\"FACTOR PROV\", \"CLAS BASE RIESGO\"]] = df_otras_marcas.apply(\n",
    "        lambda r: pd.Series(\n",
    "            calculate_otros_marcas_factor_and_class(r, df_matrices_otros_tipos)\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # 13. Calcular 'BASE RIESGO'\n",
    "    df_otras_marcas[\"BASE RIESGO\"] = df_otras_marcas.apply(calculate_base_riesgo_column, axis=1)\n",
    "    \n",
    "    # 14. Calcular 'PROVISION'\n",
    "    df_otras_marcas[\"PROVISION\"] = df_otras_marcas.apply(calculate_provision_column, axis=1)\n",
    "    \n",
    "    return df_otras_marcas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_otras_marcas= process_dataframe_otras_marcas(df_otras_marcas, df_matrices_otros_tipos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_final_dataframes(\n",
    "    df_final_avon_natura: pd.DataFrame,\n",
    "    df_final_otras_marcas: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Combina en un √∫nico DataFrame los resultados procesados para:\n",
    "      - Avon/Natura (df_final_avon_natura)\n",
    "      - Resto de marcas (df_final_otras_marcas)\n",
    "\n",
    "    Devuelve un nuevo DataFrame con todos los registros y reinicia el √≠ndice.\n",
    "    \"\"\"\n",
    "    # Verificar que tengan las mismas columnas\n",
    "    cols1 = list(df_final_avon_natura.columns)\n",
    "    cols2 = list(df_final_otras_marcas.columns)\n",
    "    if cols1 != cols2:\n",
    "        raise ValueError(\n",
    "            \"Los DataFrames no coinciden en sus columnas.\\n\"\n",
    "            f\"Avon/Natura: {cols1}\\n\"\n",
    "            f\"Otras marcas: {cols2}\"\n",
    "        )\n",
    "\n",
    "    # Concatenar uno encima del otro\n",
    "    df_final_merge = pd.concat([df_final_avon_natura, df_final_otras_marcas], ignore_index=True)\n",
    "    \n",
    "    # Columnas en el orden deseado\n",
    "    columnas_ordenadas = [\n",
    "        \"NEGOCIO INVENTARIOS\", \"A√ëO NATURAL/MES\",\"TIPO MATERIAL INVENTARIO\", \"MARCA DE QM\", \"MATERIAL\", \n",
    "        \"DESCRIPCI√ìN\", \"UNIDAD MEDIDA\", \"CENTRO\", \"CODIGO ALMACEN CLIENTE\", \"INDICADOR STOCK ESPEC.\",\n",
    "        \"N√öM.STOCK.ESP.\", \"LOTE\", \"CREADO EL\", \"FECH. FABRICACI√ìN\", \"FECH, CADUCIDAD/FECH PREF. CONSUMO\",\n",
    "        \"FECHA BLOQUEADO\", \"FECHA OBSOLETO\", \"FECHA ENTRADA\", \"RANGO OBSOLETO 2\", \"RANGO COBERTURA\",\n",
    "        \"RANGO DE PERMANENCIA\", \"RANGO BLOQUEADO\", \"RANGO OBSOLETO\", \"RANGO VENCIDOS\", \"PR√ìXIMO A VENCER\",\n",
    "        \"RANGO PR√ìX.VENCER MM\", \"RANGO PR√ìXIMOS A VEN\", \"TIPO DE MATERIAL (I)\", \"COSTO UNITARIO REAL\",\n",
    "        \"INVENTARIO DISPONIBL\", \"INVENTARIO NO DISPON\", \"VALOR OBSOLETO\", \"VALOR BLOQUEADO MM\", \"VALOR TOTAL MM\", \"PERMANENCIA\",\n",
    "\n",
    "        \"TIEMPO BLOQUEADO\",\"MARCA CONCAT\", \"SEGMENTACION\", \"SUBSEGMENTACION\",  \n",
    "        \"RANGO DE PERMANENCIA 2\",\n",
    "        \"STATUS CONS\", \"VALOR DEF\", \"RANGO OBSOLESCENCIA\", \"RANGO VENCIDO 2\",\n",
    "        \"RANGO BLOQUEADO 2\", \"RANGO CONS\",  \n",
    "        \"FACTOR PROV\", \"CLAS BASE RIESGO\", \"BASE RIESGO\", \"PROVISION\" \n",
    "    ]\n",
    "    \n",
    "    # Renombrar columnas duplicadas autom√°ticamente\n",
    "    nuevos_nombres = []\n",
    "    conteo = {}\n",
    "    for col in df_final_merge.columns:\n",
    "        if col in conteo:\n",
    "            conteo[col] += 1\n",
    "            nuevos_nombres.append(f\"{col}_{conteo[col]}\")\n",
    "        else:\n",
    "            conteo[col] = 0\n",
    "            nuevos_nombres.append(col)\n",
    "    df_final_merge.columns = nuevos_nombres\n",
    "    \n",
    "    df_final_merge = df_final_merge.reindex(columns=columnas_ordenadas)\n",
    "\n",
    "    return df_final_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_full_inventory(\n",
    "    df_final_combined: pd.DataFrame,\n",
    "    df_matrices_avon_natura: pd.DataFrame,\n",
    "    df_matrices_otros_tipos: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Ejecuta todo el procesamiento de inventario:\n",
    "      1) Transformaciones comunes (mapear marcas, rangos, estados, fechas‚Ä¶)\n",
    "      2) C√°lculo de factor_prov y clas_base_riesgo con la l√≥gica AVON/NATURA\n",
    "         sobre los registros de esas marcas\n",
    "      3) C√°lculo de factor_prov y clas_base_riesgo con la l√≥gica resto de marcas\n",
    "         sobre el resto de registros\n",
    "      4) C√°lculo final de base_riesgo y provision\n",
    "    No se altera ninguna de las funciones de negocio (calculate_‚Ä¶).\n",
    "    \"\"\"\n",
    "    df = df_final_combined.copy()\n",
    "\n",
    "    # --- 1. TRANSFORMACIONES COMUNES ---\n",
    "    # 1.1 mapeos iniciales\n",
    "    df[\"MARCA CONCAT\"]        = df[\"MARCA DE QM\"].map(insert_marks()).fillna(\"\")\n",
    "    df[\"SEGMENTACION\"]        = df[\"MARCA DE QM\"].map(insert_segments()).fillna(\"OTRAS\")\n",
    "    df[\"SUBSEGMENTACION\"]     = df[\"MARCA DE QM\"].map(insert_subsegmentacion()).fillna(\"\")\n",
    "\n",
    "    # 1.2 rangos, estados y valores\n",
    "    df[\"RANGO DE PERMANENCIA 2\"] = df.apply(calculate_rango_permanencia, axis=1)\n",
    "    df[\"STATUS CONS\"]            = df.apply(calculate_status_cons,      axis=1)\n",
    "    df[\"VALOR DEF\"]              = df.apply(calculate_valor_def,        axis=1)\n",
    "\n",
    "    # 1.3 limpieza y fechas\n",
    "    df.replace(\"#\", np.nan, inplace=True)\n",
    "    for col in [\n",
    "        \"FECHA ENTRADA\",\"FECHA OBSOLETO\",\"FECHA BLOQUEADO\",\n",
    "        \"FECH. FABRICACI√ìN\",\"CREADO EL\",\"FECH, CADUCIDAD/FECH PREF. CONSUMO\"\n",
    "    ]:\n",
    "        if col in df:\n",
    "            df[col] = pd.to_datetime(df[col], format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "\n",
    "    # 1.4 rangos avanzados\n",
    "    df[\"RANGO OBSOLESCENCIA\"] = df.apply(calculate_rango_obsolescencia, axis=1)\n",
    "    df[\"RANGO VENCIDO 2\"]     = df.apply(calculate_rango_vencido,  axis=1)\n",
    "    df[\"RANGO BLOQUEADO 2\"]   = df.apply(calculate_rango_bloqueado,axis=1)\n",
    "    df[\"RANGO CONS\"]          = df.apply(calculate_rango_cons,     axis=1)\n",
    "    df[\"TIEMPO BLOQUEADO\"]    = df.apply(calculate_tiempo_bloqueo,axis=1)\n",
    "\n",
    "    # inicializamos resultados\n",
    "    df[\"FACTOR PROV\"]        = 0.0\n",
    "    df[\"CLAS BASE RIESGO\"]   = \"BAJO\"\n",
    "\n",
    "    # --- 2. PREPARAR LOOKUPS ---\n",
    "    # AVON / NATURA: lookup por concatenado ‚Üí (factor,clas)\n",
    "    lookup_avon = {\n",
    "        str(r[\"concatenado\"]).strip(): (r[\"factor_prov\"], r[\"clasificacion\"])\n",
    "        for _, r in df_matrices_avon_natura.iterrows()\n",
    "    }\n",
    "    # resto de marcas: pasamos el DataFrame para filtrados por tipo_matriz\n",
    "    df_mat_otros = df_matrices_otros_tipos.copy()\n",
    "\n",
    "    # --- 3. APLICAR L√ìGICA SEG√öN MARCA ---\n",
    "    mask_avon = df[\"MARCA DE QM\"].str.upper().isin([\"AVON\", \"NATURA\"])\n",
    "\n",
    "    # 3.1 AVON/NATURA\n",
    "    df.loc[mask_avon, [\"FACTOR PROV\",\"CLAS BASE RIESGO\"]] = (\n",
    "        df.loc[mask_avon]\n",
    "          .apply(lambda row: pd.Series(\n",
    "               calculate_avon_natura_factor_and_class(row, lookup_avon)\n",
    "           ), axis=1)\n",
    "    )\n",
    "\n",
    "    # 3.2 RESTO DE MARCAS\n",
    "    df.loc[~mask_avon, [\"FACTOR PROV\",\"CLAS BASE RIESGO\"]] = (\n",
    "        df.loc[~mask_avon]\n",
    "          .apply(lambda row: pd.Series(\n",
    "               calculate_otros_marcas_factor_and_class(row, df_mat_otros)\n",
    "           ), axis=1)\n",
    "    )\n",
    "\n",
    "    # --- 4. C√ÅLCULOS FINALES ---\n",
    "    df[\"BASE RIESGO\"] = df.apply(calculate_base_riesgo_column,    axis=1)\n",
    "    df[\"PROVISION\"]   = df.apply(calculate_provision_column,      axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo Excel creado exitosamente: C:\\Users\\prac.planeacionfi\\OneDrive - Prebel S.A BIC\\Escritorio\\PRUEBAS BASE RIESGO\\An√°lisis_BaseRiesgo_Final_15-05-2025.xlsx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\prac.planeacionfi\\\\OneDrive - Prebel S.A BIC\\\\Escritorio\\\\PRUEBAS BASE RIESGO\\\\An√°lisis_BaseRiesgo_Final_15-05-2025.xlsx'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = process_full_inventory(df_final_combined, df_matrices_avon_natura, df_matrices_otros_tipos)\n",
    "export_dataframe_to_excel(df_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
